{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"bs_cupid_try version 2 \u00b6 A Python package to solve, simulate and estimate separable matching models Free software: MIT license Documentation: https://bsalanie.github.io/bs_cupid_try See also: An interactive Streamlit app Installation \u00b6 1 pip install -U bs_cupid_try Accessing the code \u00b6 For instance: 1 from bs_cupid_try.min_distance import estimate_semilinear_mde An example \u00b6 We create a Choo-Siow market; we solve for the stable matching in an infinite ppulation using IPFP; we simulate a sample drawn from the stable matching and we estimate the coefficients of the basis functions using both minimum distance and Poisson GLM estimators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np from bs_cupid_try.model_classes import ChooSiowPrimitives from bs_cupid_try.choo_siow import entropy_choo_siow from bs_cupid_try.min_distance import estimate_semilinear_mde from bs_cupid_try.poisson_glm import choo_siow_poisson_glm X , Y , K = 10 , 20 , 2 # we simulate a Choo and Siow population # with 10 types of men and 20 types of women # with equal numbers of men and women of each type # and two random basis functions lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) matching_popu = choo_siow_instance . ipfp_solve () muxy_popu , mux0_popu , mu0y_popu , n_popu , m_popu \\ = matching_popu . unpack () # we simulate the market on a finite population n_households = int ( 1e6 ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () # We estimate the parameters using minimum distance mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_choo_siow , more_params = None ) # we print and check the results mde_discrepancy = mde_results . print_results ( true_coeffs = lambda_true , n_alpha = 0 ) # we also estimate using Poisson GLM poisson_results = choo_siow_poisson_glm ( mus_sim , phi_bases ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim \\ = mus_sim . unpack () poisson_discrepancy = poisson_results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) )","title":"Home"},{"location":"#bs_cupid_try-version-2","text":"A Python package to solve, simulate and estimate separable matching models Free software: MIT license Documentation: https://bsalanie.github.io/bs_cupid_try See also: An interactive Streamlit app","title":"bs_cupid_try version 2"},{"location":"#installation","text":"1 pip install -U bs_cupid_try","title":"Installation"},{"location":"#accessing-the-code","text":"For instance: 1 from bs_cupid_try.min_distance import estimate_semilinear_mde","title":"Accessing the code"},{"location":"#an-example","text":"We create a Choo-Siow market; we solve for the stable matching in an infinite ppulation using IPFP; we simulate a sample drawn from the stable matching and we estimate the coefficients of the basis functions using both minimum distance and Poisson GLM estimators. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np from bs_cupid_try.model_classes import ChooSiowPrimitives from bs_cupid_try.choo_siow import entropy_choo_siow from bs_cupid_try.min_distance import estimate_semilinear_mde from bs_cupid_try.poisson_glm import choo_siow_poisson_glm X , Y , K = 10 , 20 , 2 # we simulate a Choo and Siow population # with 10 types of men and 20 types of women # with equal numbers of men and women of each type # and two random basis functions lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) matching_popu = choo_siow_instance . ipfp_solve () muxy_popu , mux0_popu , mu0y_popu , n_popu , m_popu \\ = matching_popu . unpack () # we simulate the market on a finite population n_households = int ( 1e6 ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () # We estimate the parameters using minimum distance mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_choo_siow , more_params = None ) # we print and check the results mde_discrepancy = mde_results . print_results ( true_coeffs = lambda_true , n_alpha = 0 ) # we also estimate using Poisson GLM poisson_results = choo_siow_poisson_glm ( mus_sim , phi_bases ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim \\ = mus_sim . unpack () poisson_discrepancy = poisson_results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) )","title":"An example"},{"location":"choo_siow/","text":"choo_siow module \u00b6 The components of the derivative of the entropy for the Choo and Siow homoskedastic model. e0_fun_choo_siow ( muhat ) \u00b6 Returns the values of $e_0$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the first derivative of the entropy Source code in bs_cupid_try/choo_siow.py 92 93 94 95 96 97 98 99 100 101 102 def e0_fun_choo_siow ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 1 ) return entropy_res [ 1 ] hessian_mumu_choo_siow ( muhat ) \u00b6 Returns the derivatives of $e_0$ in $\\mu$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy ThreeArrays and the two components of the hessian wrt $(\\mu,r)$ Source code in bs_cupid_try/choo_siow.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def hessian_mumu_choo_siow ( muhat : Matching ) -> ThreeArrays : \"\"\"Returns the derivatives of $e_0$ in $\\mu$ for the Choo and Siow model. Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy and the two components of the hessian wrt $(\\mu,r)$ \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmumu = entropy_res [ 2 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] return hess_x , hess_y , hess_xy hessian_mur_choo_siow ( muhat ) \u00b6 Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the two components of the hessian wrt $(\\mu,r)$ of the entropy Source code in bs_cupid_try/choo_siow.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 def hessian_mur_choo_siow ( muhat : Matching ) -> TwoArrays : \"\"\"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model. Args: muhat: a Matching Returns: the two components of the hessian wrt $(\\mu,r)$ of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmur = entropy_res [ 3 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2r = hessmur [ x , y , :] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return hess_nx , hess_my","title":"Choo-Siow homoskedastic"},{"location":"choo_siow/#choo_siow-module","text":"The components of the derivative of the entropy for the Choo and Siow homoskedastic model.","title":"choo_siow module"},{"location":"choo_siow/#bs_cupid_try.choo_siow.e0_fun_choo_siow","text":"Returns the values of $e_0$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the first derivative of the entropy Source code in bs_cupid_try/choo_siow.py 92 93 94 95 96 97 98 99 100 101 102 def e0_fun_choo_siow ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 1 ) return entropy_res [ 1 ]","title":"e0_fun_choo_siow()"},{"location":"choo_siow/#bs_cupid_try.choo_siow.hessian_mumu_choo_siow","text":"Returns the derivatives of $e_0$ in $\\mu$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy ThreeArrays and the two components of the hessian wrt $(\\mu,r)$ Source code in bs_cupid_try/choo_siow.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def hessian_mumu_choo_siow ( muhat : Matching ) -> ThreeArrays : \"\"\"Returns the derivatives of $e_0$ in $\\mu$ for the Choo and Siow model. Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\mu,\\mu)$ of the entropy and the two components of the hessian wrt $(\\mu,r)$ \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmumu = entropy_res [ 2 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] return hess_x , hess_y , hess_xy","title":"hessian_mumu_choo_siow()"},{"location":"choo_siow/#bs_cupid_try.choo_siow.hessian_mur_choo_siow","text":"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the two components of the hessian wrt $(\\mu,r)$ of the entropy Source code in bs_cupid_try/choo_siow.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 def hessian_mur_choo_siow ( muhat : Matching ) -> TwoArrays : \"\"\"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model. Args: muhat: a Matching Returns: the two components of the hessian wrt $(\\mu,r)$ of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmur = entropy_res [ 3 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2r = hessmur [ x , y , :] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return hess_nx , hess_my","title":"hessian_mur_choo_siow()"},{"location":"choo_siow_gender_heteroskedastic/","text":"choo_siow_gender_heteroskedastic module \u00b6 The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model. We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side. e0_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def e0_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () e0_vals = - np . log ( muxy / mux0 . reshape (( - 1 , 1 ))) return e0_vals e0_derivative_mu_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ in $\\mu$. for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def e0_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ in $\\mu$. for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_x [ x , y , :] = - dlogx0 hess_xy [ x , y ] = - der_logxy [ x , y ] - dlogx0 return hess_x , hess_y , hess_xy e0_derivative_r_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def e0_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y ] = dlogx0 return hess_n , hess_m e_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,1) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def e_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 e_vals = np . zeros (( X , Y , n_alpha )) e_vals [:, :, 0 ] = - np . log ( muxy / mu0y ) return e_vals e_derivative_mu_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def e_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_y [ x , y , :, 0 ] = - dlog0y hess_xy [ x , y , 0 ] = - der_logxy [ x , y ] - dlog0y return hess_x , hess_y , hess_xy e_derivative_r_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$ Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def e_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,r)$ \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_m [ x , y , 0 ] = dlog0y return hess_n , hess_m","title":"Choo-Siow Gender-heteroskedastic"},{"location":"choo_siow_gender_heteroskedastic/#choo_siow_gender_heteroskedastic-module","text":"The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model. We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side.","title":"choo_siow_gender_heteroskedastic module"},{"location":"choo_siow_gender_heteroskedastic/#bs_cupid_try.choo_siow_gender_heteroskedastic.e0_choo_siow_gender_heteroskedastic","text":"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def e0_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () e0_vals = - np . log ( muxy / mux0 . reshape (( - 1 , 1 ))) return e0_vals","title":"e0_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#bs_cupid_try.choo_siow_gender_heteroskedastic.e0_derivative_mu_gender_heteroskedastic","text":"Returns the derivatives of the parameter-independent part $e_0$ in $\\mu$. for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def e0_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ in $\\mu$. for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_x [ x , y , :] = - dlogx0 hess_xy [ x , y ] = - der_logxy [ x , y ] - dlogx0 return hess_x , hess_y , hess_xy","title":"e0_derivative_mu_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#bs_cupid_try.choo_siow_gender_heteroskedastic.e0_derivative_r_gender_heteroskedastic","text":"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def e0_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y ] = dlogx0 return hess_n , hess_m","title":"e0_derivative_r_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#bs_cupid_try.choo_siow_gender_heteroskedastic.e_choo_siow_gender_heteroskedastic","text":"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,1) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def e_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 e_vals = np . zeros (( X , Y , n_alpha )) e_vals [:, :, 0 ] = - np . log ( muxy / mu0y ) return e_vals","title":"e_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#bs_cupid_try.choo_siow_gender_heteroskedastic.e_derivative_mu_gender_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def e_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_y [ x , y , :, 0 ] = - dlog0y hess_xy [ x , y , 0 ] = - der_logxy [ x , y ] - dlog0y return hess_x , hess_y , hess_xy","title":"e_derivative_mu_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#bs_cupid_try.choo_siow_gender_heteroskedastic.e_derivative_r_gender_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$ Source code in bs_cupid_try/choo_siow_gender_heteroskedastic.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def e_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,r)$ \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_m [ x , y , 0 ] = dlog0y return hess_n , hess_m","title":"e_derivative_r_gender_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/","text":"choo_siow_heteroskedastic module \u00b6 The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model. We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side. e0_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy Source code in bs_cupid_try/choo_siow_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def e0_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy \"\"\" muxy , mux0 , * _ = muhat . unpack () mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] e0_vals = np . zeros_like ( muxy ) e0_vals [ 0 , :] = - np . log ( mu1y / mu10 ) return e0_vals e0_derivative_mu_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt $(\\mu, \\mu)$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def e0_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu, \\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_log1y = 1.0 / mu1y der_log10 = 1.0 / mu10 for y in range ( Y ): hess_x [ 0 , y , :] = - der_log10 hess_xy [ 0 , y ] = - der_log1y [ y ] - der_log10 return hess_x , hess_y , hess_xy e0_derivative_r_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def e0_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu10 = mux0 [ 0 ] hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_log10 = 1.0 / mu10 for y in range ( Y ): hess_n [ 0 , y ] = der_log10 return hess_n , hess_m e_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def e_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 e_vals = np . zeros (( X , Y , n_alpha )) i = 0 for x in range ( 1 , X ): e_vals [ x , :, i ] = - np . log ( muxy [ x , :] / mux0 [ x ]) i += 1 for y in range ( Y ): e_vals [:, y , i ] = - np . log ( muxy [:, y ] / mu0y [ y ]) i += 1 return e_vals e_derivative_mu_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def e_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] dlogxy = der_logxy [ x , :] for y in range ( Y ): hess_x [ x , y , :, i ] = - dlogx0 hess_xy [ x , y , i ] = - dlogxy [ y ] - dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] dlogxy = der_logxy [:, y ] for x in range ( X ): hess_y [ x , y , :, i ] = - dlog0y hess_xy [ x , y , i ] = - dlogxy [ x ] - dlog0y i += 1 return hess_x , hess_y , hess_xy e_derivative_r_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt $r$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def e_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $r$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y , i ] = dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] for x in range ( X ): hess_m [ x , y , i ] = dlog0y i += 1 return hess_n , hess_m","title":"Choo-Siow Heteroskedastic"},{"location":"choo_siow_heteroskedastic/#choo_siow_heteroskedastic-module","text":"The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model. We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side.","title":"choo_siow_heteroskedastic module"},{"location":"choo_siow_heteroskedastic/#bs_cupid_try.choo_siow_heteroskedastic.e0_choo_siow_heteroskedastic","text":"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy Source code in bs_cupid_try/choo_siow_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def e0_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy \"\"\" muxy , mux0 , * _ = muhat . unpack () mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] e0_vals = np . zeros_like ( muxy ) e0_vals [ 0 , :] = - np . log ( mu1y / mu10 ) return e0_vals","title":"e0_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#bs_cupid_try.choo_siow_heteroskedastic.e0_derivative_mu_heteroskedastic","text":"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt $(\\mu, \\mu)$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def e0_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu, \\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_log1y = 1.0 / mu1y der_log10 = 1.0 / mu10 for y in range ( Y ): hess_x [ 0 , y , :] = - der_log10 hess_xy [ 0 , y ] = - der_log1y [ y ] - der_log10 return hess_x , hess_y , hess_xy","title":"e0_derivative_mu_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#bs_cupid_try.choo_siow_heteroskedastic.e0_derivative_r_heteroskedastic","text":"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def e0_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu10 = mux0 [ 0 ] hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_log10 = 1.0 / mu10 for y in range ( Y ): hess_n [ 0 , y ] = der_log10 return hess_n , hess_m","title":"e0_derivative_r_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#bs_cupid_try.choo_siow_heteroskedastic.e_choo_siow_heteroskedastic","text":"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def e_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 e_vals = np . zeros (( X , Y , n_alpha )) i = 0 for x in range ( 1 , X ): e_vals [ x , :, i ] = - np . log ( muxy [ x , :] / mux0 [ x ]) i += 1 for y in range ( Y ): e_vals [:, y , i ] = - np . log ( muxy [:, y ] / mu0y [ y ]) i += 1 return e_vals","title":"e_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#bs_cupid_try.choo_siow_heteroskedastic.e_derivative_mu_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def e_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] dlogxy = der_logxy [ x , :] for y in range ( Y ): hess_x [ x , y , :, i ] = - dlogx0 hess_xy [ x , y , i ] = - dlogxy [ y ] - dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] dlogxy = der_logxy [:, y ] for x in range ( X ): hess_y [ x , y , :, i ] = - dlog0y hess_xy [ x , y , i ] = - dlogxy [ x ] - dlog0y i += 1 return hess_x , hess_y , hess_xy","title":"e_derivative_mu_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#bs_cupid_try.choo_siow_heteroskedastic.e_derivative_r_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt $r$. Source code in bs_cupid_try/choo_siow_heteroskedastic.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def e_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $r$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y , i ] = dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] for x in range ( X ): hess_m [ x , y , i ] = dlog0y i += 1 return hess_n , hess_m","title":"e_derivative_r_heteroskedastic()"},{"location":"entropy/","text":"entropy module \u00b6 Entropies and their derivatives. EntropyHessianComponents = tuple [ ThreeArrays , TwoArrays ] module-attribute \u00b6 combines the tuples of the values of the components of the hessians. EntropyHessianMuMu = Callable [[ Matching ], ThreeArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt $(\\mu,\\mu)$. EntropyHessianMuMuParam = Callable [[ Matching , list [ Any ]], ThreeArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and a list of additional parameters and returns the three components of the hessian of the entropy wrt $(\\mu,\\mu)$. EntropyHessianMuR = Callable [[ Matching ], TwoArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$. EntropyHessianMuRParam = Callable [[ Matching , list [ Any ]], TwoArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and a list of additional parameters and returns the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$. EntropyHessians = tuple [ EntropyHessianMuMu , EntropyHessianMuR ] module-attribute \u00b6 combines the hessian functions EntropyHessiansParam = tuple [ EntropyHessianMuMuParam , EntropyHessianMuRParam ] module-attribute \u00b6 combines the hessian functions when additional parameters are used EntropyFunctions dataclass \u00b6 Defines the entropy used, via the derivative $e_0 + e \\cdot \\alpha$ Attributes: Name Type Description e0_fun MatchingFunction | MatchingFunctionParam required parameter_dependent bool if True , the entropy depends on parameters. Defaults to False e_fun Optional [ MatchingFunction | MatchingFunctionParam ] only in entropies that depend on parameters. Defaults to None hessian Optional [ str ] defaults to \"numeric\" * if \"provided\" , we provide the hessian of the entropy. * if \"numerical\" , it is computed by central differences. e0_derivative Optional [ EntropyHessians | EntropyHessiansParam ] the derivative of e0_fun , if available. Defaults to None e_derivative Optional [ EntropyHessians | EntropyHessiansParam ] the derivative of e_fun , if available. Defaults to None additional_parameters Optional [ list ] additional parameters that define the distribution of errors. Defaults to None description Optional [ str ] some text describing the model. Defaults to None Examples: See entropy_choo_siow in choo_siow.py Source code in bs_cupid_try/entropy.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @dataclass class EntropyFunctions : \"\"\"Defines the entropy used, via the derivative $e_0 + e \\cdot \\\\alpha$ Attributes: e0_fun: required parameter_dependent: if `True`, the entropy depends on parameters. Defaults to `False` e_fun: only in entropies that depend on parameters. Defaults to `None` hessian: defaults to `\"numeric\"` * if `\"provided\"`, we provide the hessian of the entropy. * if `\"numerical\"`, it is computed by central differences. e0_derivative: the derivative of `e0_fun`, if available. Defaults to `None` e_derivative: the derivative of `e_fun`, if available. Defaults to `None` additional_parameters: additional parameters that define the distribution of errors. Defaults to `None` description: some text describing the model. Defaults to `None` Examples: See `entropy_choo_siow` in `choo_siow.py` \"\"\" e0_fun : MatchingFunction | MatchingFunctionParam e0_derivative : Optional [ EntropyHessians | EntropyHessiansParam ] = None additional_parameters : Optional [ list ] = None description : Optional [ str ] = None e_fun : Optional [ MatchingFunction | MatchingFunctionParam ] = None e_derivative : Optional [ EntropyHessians | EntropyHessiansParam ] = None hessian : Optional [ str ] = \"numerical\" parameter_dependent : bool = False def __post_init__ ( self ): if not self . parameter_dependent : if self . hessian == \"provided\" and self . e0_derivative is None : bs_error_abort ( \"You claim to provide the hessian \" + \"but you did not provide the e0_derivative.\" ) else : if self . e_fun is None : bs_error_abort ( \"Your entropy is parameter dependent \" + \" but you did not provide the e_fun.\" ) if self . hessian == \"provided\" and self . e_derivative is None : bs_error_abort ( \"Your entropy is parameter dependent, \" + \"you claim to provide the hessian, \\n \" + \" but I do not see the e_derivative.\" ) entropy_gradient ( entropy , muhat , alpha = None , additional_parameters = None ) \u00b6 Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \u0007lpha, p)$ Parameters: Name Type Description Default entropy EntropyFunctions the EntropyFunctions object required muhat Matching a Matching required alpha Optional [ np . ndarray ] a vector of parameters of the derivative of the entropy, if any None additional_parameters Optional [ list ] a list of additional parameters p , if any None Returns: Type Description np . ndarray the derivative of the entropy wrt $\\mu$ np . ndarray at $(\\mu, n, m, \u0007lpha, p)$. Source code in bs_cupid_try/entropy.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def entropy_gradient ( entropy : EntropyFunctions , muhat : Matching , alpha : Optional [ np . ndarray ] = None , additional_parameters : Optional [ list ] = None , ) -> np . ndarray : \"\"\"Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha, p)$ Args: entropy: the `EntropyFunctions` object muhat: a Matching alpha: a vector of parameters of the derivative of the entropy, if any additional_parameters: a list of additional parameters `p`, if any Returns: the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha, p)$. \"\"\" e0_fun = entropy . e0_fun if additional_parameters is not None : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) else : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) parameter_dependent = entropy . parameter_dependent if parameter_dependent : if alpha is None : bs_error_abort ( \"alpha should be specified for this model\" ) e_fun = entropy . e_fun if e_fun is None : bs_error_abort ( \"we should have an e_fun in this model\" ) else : if additional_parameters is not None : e_fun = cast ( MatchingFunctionParam , e_fun ) e_vals = e_fun ( muhat , additional_parameters ) else : e_fun = cast ( MatchingFunction , e_fun ) e_vals = e_fun ( muhat ) return e0_vals + e_vals @ alpha else : return e0_vals","title":"Entropy utilities"},{"location":"entropy/#entropy-module","text":"Entropies and their derivatives.","title":"entropy module"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessianComponents","text":"combines the tuples of the values of the components of the hessians.","title":"EntropyHessianComponents"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessianMuMu","text":"The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt $(\\mu,\\mu)$.","title":"EntropyHessianMuMu"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessianMuMuParam","text":"The type of a function that takes in a Matching and a list of additional parameters and returns the three components of the hessian of the entropy wrt $(\\mu,\\mu)$.","title":"EntropyHessianMuMuParam"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessianMuR","text":"The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$.","title":"EntropyHessianMuR"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessianMuRParam","text":"The type of a function that takes in a Matching and a list of additional parameters and returns the two components of the hessian of the entropy wrt $(\\mu,n)$ and $(\\mu, m))$.","title":"EntropyHessianMuRParam"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessians","text":"combines the hessian functions","title":"EntropyHessians"},{"location":"entropy/#bs_cupid_try.entropy.EntropyHessiansParam","text":"combines the hessian functions when additional parameters are used","title":"EntropyHessiansParam"},{"location":"entropy/#bs_cupid_try.entropy.EntropyFunctions","text":"Defines the entropy used, via the derivative $e_0 + e \\cdot \\alpha$ Attributes: Name Type Description e0_fun MatchingFunction | MatchingFunctionParam required parameter_dependent bool if True , the entropy depends on parameters. Defaults to False e_fun Optional [ MatchingFunction | MatchingFunctionParam ] only in entropies that depend on parameters. Defaults to None hessian Optional [ str ] defaults to \"numeric\" * if \"provided\" , we provide the hessian of the entropy. * if \"numerical\" , it is computed by central differences. e0_derivative Optional [ EntropyHessians | EntropyHessiansParam ] the derivative of e0_fun , if available. Defaults to None e_derivative Optional [ EntropyHessians | EntropyHessiansParam ] the derivative of e_fun , if available. Defaults to None additional_parameters Optional [ list ] additional parameters that define the distribution of errors. Defaults to None description Optional [ str ] some text describing the model. Defaults to None Examples: See entropy_choo_siow in choo_siow.py Source code in bs_cupid_try/entropy.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @dataclass class EntropyFunctions : \"\"\"Defines the entropy used, via the derivative $e_0 + e \\cdot \\\\alpha$ Attributes: e0_fun: required parameter_dependent: if `True`, the entropy depends on parameters. Defaults to `False` e_fun: only in entropies that depend on parameters. Defaults to `None` hessian: defaults to `\"numeric\"` * if `\"provided\"`, we provide the hessian of the entropy. * if `\"numerical\"`, it is computed by central differences. e0_derivative: the derivative of `e0_fun`, if available. Defaults to `None` e_derivative: the derivative of `e_fun`, if available. Defaults to `None` additional_parameters: additional parameters that define the distribution of errors. Defaults to `None` description: some text describing the model. Defaults to `None` Examples: See `entropy_choo_siow` in `choo_siow.py` \"\"\" e0_fun : MatchingFunction | MatchingFunctionParam e0_derivative : Optional [ EntropyHessians | EntropyHessiansParam ] = None additional_parameters : Optional [ list ] = None description : Optional [ str ] = None e_fun : Optional [ MatchingFunction | MatchingFunctionParam ] = None e_derivative : Optional [ EntropyHessians | EntropyHessiansParam ] = None hessian : Optional [ str ] = \"numerical\" parameter_dependent : bool = False def __post_init__ ( self ): if not self . parameter_dependent : if self . hessian == \"provided\" and self . e0_derivative is None : bs_error_abort ( \"You claim to provide the hessian \" + \"but you did not provide the e0_derivative.\" ) else : if self . e_fun is None : bs_error_abort ( \"Your entropy is parameter dependent \" + \" but you did not provide the e_fun.\" ) if self . hessian == \"provided\" and self . e_derivative is None : bs_error_abort ( \"Your entropy is parameter dependent, \" + \"you claim to provide the hessian, \\n \" + \" but I do not see the e_derivative.\" )","title":"EntropyFunctions"},{"location":"entropy/#bs_cupid_try.entropy.entropy_gradient","text":"Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \u0007lpha, p)$ Parameters: Name Type Description Default entropy EntropyFunctions the EntropyFunctions object required muhat Matching a Matching required alpha Optional [ np . ndarray ] a vector of parameters of the derivative of the entropy, if any None additional_parameters Optional [ list ] a list of additional parameters p , if any None Returns: Type Description np . ndarray the derivative of the entropy wrt $\\mu$ np . ndarray at $(\\mu, n, m, \u0007lpha, p)$. Source code in bs_cupid_try/entropy.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def entropy_gradient ( entropy : EntropyFunctions , muhat : Matching , alpha : Optional [ np . ndarray ] = None , additional_parameters : Optional [ list ] = None , ) -> np . ndarray : \"\"\"Computes the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha, p)$ Args: entropy: the `EntropyFunctions` object muhat: a Matching alpha: a vector of parameters of the derivative of the entropy, if any additional_parameters: a list of additional parameters `p`, if any Returns: the derivative of the entropy wrt $\\mu$ at $(\\mu, n, m, \\alpha, p)$. \"\"\" e0_fun = entropy . e0_fun if additional_parameters is not None : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) else : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) parameter_dependent = entropy . parameter_dependent if parameter_dependent : if alpha is None : bs_error_abort ( \"alpha should be specified for this model\" ) e_fun = entropy . e_fun if e_fun is None : bs_error_abort ( \"we should have an e_fun in this model\" ) else : if additional_parameters is not None : e_fun = cast ( MatchingFunctionParam , e_fun ) e_vals = e_fun ( muhat , additional_parameters ) else : e_fun = cast ( MatchingFunction , e_fun ) e_vals = e_fun ( muhat ) return e0_vals + e_vals @ alpha else : return e0_vals","title":"entropy_gradient()"},{"location":"ipfp_solvers/","text":"ipfp_solvers module \u00b6 Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the Choo and Siow 2006 <https://www.jstor.org/stable/10.1086/498585?seq=1> _ model: homoskedastic with singles (as in Choo and Siow 2006) homoskedastic without singles gender-heteroskedastic: with a scale parameter on the error term for women gender- and type-heteroskedastic: with a scale parameter on the error term for each gender and type two-level nested logit, with nests and nest parameters that do not depend on the type, and {0} as the first nest Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using gr=True ) the derivatives of the matching patterns in all primitives. ipfp_gender_heteroskedastic_solver ( Phi , men_margins , women_margins , tau , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter tau Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tau float the standard error for all women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, tau) if gr is True Source code in bs_cupid_try/ipfp_solvers.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 def ipfp_gender_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tau : float , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter `tau` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tau: the standard error for all women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if tau <= 0 : bs_error_abort ( f \"We need a positive tau, not { tau } \" ) ############################################################################# # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau ############################################################################# sigma_x = np . ones ( X ) tau_y = np . full ( Y , tau ) if gr : ( mus_hxy , marg_err_x , marg_err_y , dmus_xy , dmus_x0 , dmus_0y , ) = ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = True , maxiter = maxiter , verbose = verbose , ) muxy , _ , _ , _ , _ = mus_hxy . unpack () n_sum_categories = X + Y n_prod_categories = X * Y n_cols = n_sum_categories + n_prod_categories itau_y = n_cols + X dmuxy = np . zeros (( n_prod_categories , n_cols + 1 )) dmuxy [:, : n_cols ] = dmus_xy [:, : n_cols ] dmuxy [:, - 1 ] = np . sum ( dmus_xy [:, itau_y :], 1 ) dmux0 = np . zeros (( X , n_cols + 1 )) dmux0 [:, : n_cols ] = dmus_x0 [:, : n_cols ] dmux0 [:, - 1 ] = np . sum ( dmus_x0 [:, itau_y :], 1 ) dmu0y = np . zeros (( Y , n_cols + 1 )) dmu0y [:, : n_cols ] = dmus_0y [:, : n_cols ] dmu0y [:, - 1 ] = np . sum ( dmus_0y [:, itau_y :], 1 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , ) else : return ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = False , maxiter = maxiter , verbose = verbose , ) ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors sigma_x and tau_y Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required sigma_x np . ndarray the vector of standard errors for the X types of men required sigma_x np . ndarray the vector of standard errors for Y types of women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, sigma_x, tau_y) IPFPNoGradientResults | IPFPGradientResults if gr is True Source code in bs_cupid_try/ipfp_solvers.py 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 def ipfp_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , sigma_x : np . ndarray , tau_y : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors `sigma_x` and `tau_y` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) sigma_x: the vector of standard errors for the X types of men sigma_x: the vector of standard errors for Y types of women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if np . min ( sigma_x ) <= 0.0 : bs_error_abort ( \"All elements of sigma_x must be positive\" ) if np . min ( tau_y ) <= 0.0 : bs_error_abort ( \"All elements of tau_y must be positive\" ) sumxy1 = 1.0 / np . add . outer ( sigma_x , tau_y ) ephi2 , der_ephi2 = npexp ( Phi * sumxy1 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # with tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi2 )) # we find the largest values of sigma_x and tau_y xmax = np . argmax ( sigma_x ) sigma_max = sigma_x [ xmax ] ymax = np . argmax ( tau_y ) tau_max = tau_y [ ymax ] # we use tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) sig_taumax = sigma_x + tau_max txi = np . power ( bigc , sigma_x / sig_taumax ) sigmax_tau = tau_y + sigma_max tyi = np . power ( bigc , tau_y / sigmax_tau ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc txin = txi . copy () mu0y_in = np . power ( np . power ( tyi , sigmax_tau ), 1.0 / tau_y ) while err_newton > tol_newton : txit = np . power ( txin , sig_taumax ) mux0_in = np . power ( txit , 1.0 / sigma_x ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y ) ) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) errxi = mux0_in + np . sum ( muxy_in , 1 ) - men_margins err_newton = npmaxabs ( errxi ) txin -= errxi / ( sig_taumax * ( mux0_in / sigma_x + np . sum ( sumxy1 * muxy_in , 1 )) / txin ) tx = txin # Newton iterates for women err_newton = bigc tyin = tyi . copy () mux0_in = np . power ( np . power ( tx , sig_taumax ), 1.0 / sigma_x ) while err_newton > tol_newton : tyit = np . power ( tyin , sigmax_tau ) mu0y_in = np . power ( tyit , 1.0 / tau_y ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y ) ) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) erryi = mu0y_in + np . sum ( muxy_in , 0 ) - women_margins err_newton = npmaxabs ( erryi ) tyin -= erryi / ( sigmax_tau * ( mu0y_in / tau_y + np . sum ( sumxy1 * muxy_in , 0 )) / tyin ) ty = tyin err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = mux0_in mu0y = mu0y_in muxy = muxy_in marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute the derivatives n_sum_categories = X + Y n_prod_categories = X * Y # we work directly with (mux0, mu0y) sigrat_xy = sumxy1 * sigma_x . reshape (( - 1 , 1 )) taurat_xy = 1.0 - sigrat_xy mux0_mat = nprepeat_col ( mux0 , Y ) mu0y_mat = nprepeat_row ( mu0y , X ) # muxy = axy * bxy * ephi2 axy = nppow ( mux0_mat , sigrat_xy ) bxy = nppow ( mu0y_mat , taurat_xy ) der_axy1 , der_axy2 = der_nppow ( mux0_mat , sigrat_xy ) der_bxy1 , der_bxy2 = der_nppow ( mu0y_mat , taurat_xy ) der_axy1_rat , der_axy2_rat = der_axy1 / axy , der_axy2 / axy der_bxy1_rat , der_bxy2_rat = der_bxy1 / bxy , der_bxy2 / bxy # start with the LHS of the linear system on (dmux0, dmu0y) lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 1.0 + np . sum ( muxy * der_axy1_rat , 1 )) lhs [: X , X :] = muxy * der_bxy1_rat lhs [ X :, X :] = np . diag ( 1.0 + np . sum ( muxy * der_bxy1_rat , 0 )) lhs [ X :, : X ] = ( muxy * der_axy1_rat ) . T # now fill the RHS (derivatives wrt men_margins, then men_margins, # then Phi, then sigma_x and tau_y) n_cols_rhs = n_sum_categories + n_prod_categories + X + Y rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (mux0, mu0y) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (mux0, mu0y) wrt women_margins rhs [ X :, X : n_sum_categories ] = np . eye ( Y ) # the next line is sumxy1 with safeguards sumxy1_safe = sumxy1 * der_ephi2 / ephi2 big_a = muxy * sumxy1_safe big_b = der_axy2_rat - der_bxy2_rat b_mu_s = big_b * muxy * sumxy1 a_phi = Phi * big_a big_c = sumxy1 * ( a_phi - b_mu_s * tau_y ) big_d = sumxy1 * ( a_phi + b_mu_s * sigma_x . reshape (( - 1 , 1 ))) # to compute derivatives of (mux0, mu0y) wrt Phi ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - big_a [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories iend_phi = n_sum_categories + n_prod_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : iend_phi : Y ] = - big_a [:, iwoman ] ivar1 += 1 ivar2 += 1 # to compute derivatives of (mux0, mu0y) wrt sigma_x iend_sig = iend_phi + X der_sigx = np . sum ( big_c , 1 ) rhs [: X , iend_phi : iend_sig ] = np . diag ( der_sigx ) rhs [ X :, iend_phi : iend_sig ] = big_c . T # to compute derivatives of (mux0, mu0y) wrt tau_y der_tauy = np . sum ( big_d , 0 ) rhs [ X :, iend_sig :] = np . diag ( der_tauy ) rhs [: X , iend_sig :] = big_d # solve for the derivatives of mux0 and mu0y dmu0 = spla . solve ( lhs , rhs ) dmux0 = dmu0 [: X , :] dmu0y = dmu0 [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) der1 = ephi2 * der_axy1 * bxy ivar = 0 for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( der1 [ iman , :], dmux0 [ iman , :] ) ivar += Y der2 = ephi2 * der_bxy1 * axy for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( der2 [:, iwoman ], dmu0y [ iwoman , :] ) # add the terms that comes from differentiating ephi2 # on the derivative wrt Phi i = 0 j = n_sum_categories for iman in range ( X ): for iwoman in range ( Y ): dmuxy [ i , j ] += big_a [ iman , iwoman ] i += 1 j += 1 # on the derivative wrt sigma_x ivar = 0 ix = iend_phi for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), ix ] -= big_c [ iman , :] ivar += Y ix += 1 # on the derivative wrt tau_y iy = iend_sig for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , iy ] -= big_d [:, iwoman ] iy += 1 return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , ) ipfp_homoskedastic_nosingles_solver ( Phi , men_margins , women_margins , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Name Type Description muxy ThreeArrays | FourArrays the matching patterns, shape (X, Y) ThreeArrays | FourArrays marg_err_x, marg_err_y: the errors on the margins ThreeArrays | FourArrays and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if gr is True Source code in bs_cupid_try/ipfp_solvers.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def ipfp_homoskedastic_nosingles_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> ThreeArrays | FourArrays : \"\"\"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ verbose: if `True`, prints information maxiter: maximum number of iterations Returns: muxy: the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) n_couples = np . sum ( men_margins ) # check that there are as many men as women if np . abs ( np . sum ( women_margins ) - n_couples ) > n_couples * tol : bs_error_abort ( \"There should be as many men as women\" ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ephi2T = ephi2 . T ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # starting with a reasonable initial point for tx and ty: : tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# bigc = sqrt ( n_couples / np . sum ( ephi2 )) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * err_diff niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = men_margins / sx sy = ephi2T @ tx ty = women_margins / sy err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi , tyi = tx , ty niter += 1 muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = np . sum ( muxy , 1 ) - men_margins marg_err_y = np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return muxy , marg_err_x , marg_err_y else : sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = 0 for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = 0 for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = ( - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ) ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( ( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy += np . diag ( muxy_vec2 ) return muxy , marg_err_x , marg_err_y , dmuxy ipfp_homoskedastic_solver ( Phi , men_margins , women_margins , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) IPFPNoGradientResults | IPFPGradientResults if gr is True Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu , sigma = 0.0 , 1.0 n_bases = 4 bases_surplus = np . zeros (( X , Y , n_bases )) x_men = ( np . arange ( X ) - X / 2.0 ) / X y_women = ( np . arange ( Y ) - Y / 2.0 ) / Y bases_surplus [:, :, 0 ] = 1 for iy in range ( Y ): bases_surplus [:, iy , 1 ] = x_men for ix in range ( X ): bases_surplus [ ix , :, 2 ] = y_women for ix in range ( X ): for iy in range ( Y ): bases_surplus [ ix , iy , 3 ] = ( x_men [ ix ] - y_women [ iy ]) * ( x_men [ ix ] - y_women [ iy ] ) men_margins = np . random . uniform ( 1.0 , 10.0 , size = X ) women_margins = np . random . uniform ( 1.0 , 10.0 , size = Y ) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np . array ([ 3.0 , - 1.0 , - 1.0 , - 2.0 ]) true_surplus_matrix = bases_surplus @ true_surplus_params mus , marg_err_x , marg_err_y = ipfp_homoskedastic_solver ( true_surplus_matrix , men_margins , women_margins , tol = 1e-12 ) Source code in bs_cupid_try/ipfp_solvers.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 def ipfp_homoskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if `gr` is `True` Example: ```py # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu, sigma = 0.0, 1.0 n_bases = 4 bases_surplus = np.zeros((X, Y, n_bases)) x_men = (np.arange(X) - X / 2.0) / X y_women = (np.arange(Y) - Y / 2.0) / Y bases_surplus[:, :, 0] = 1 for iy in range(Y): bases_surplus[:, iy, 1] = x_men for ix in range(X): bases_surplus[ix, :, 2] = y_women for ix in range(X): for iy in range(Y): bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * ( x_men[ix] - y_women[iy] ) men_margins = np.random.uniform(1.0, 10.0, size=X) women_margins = np.random.uniform(1.0, 10.0, size=Y) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0]) true_surplus_matrix = bases_surplus @ true_surplus_params mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver( true_surplus_matrix, men_margins, women_margins, tol=1e-12 ) ``` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # where mux0=tx**2 and mu0y=ty**2 # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# ephi2T = ephi2 . T nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = sqrt ( nindivs / ( X + Y + 2.0 * np . sum ( ephi2 ))) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * bigc niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = ( np . sqrt ( sx * sx + 4.0 * men_margins ) - sx ) / 2.0 sy = ephi2T @ tx ty = ( np . sqrt ( sy * sy + 4.0 * women_margins ) - sy ) / 2.0 err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = txi * txi mu0y = tyi * tyi muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute the derivatives sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 2.0 * txi + sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( 2.0 * tyi + syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_sum_categories + n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (txi, tyi) wrt women_margins rhs [ X : n_sum_categories , X : n_sum_categories ] = np . eye ( Y ) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = ( - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ) ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of the mus dmux0 = 2.0 * ( dt * txi . reshape (( - 1 , 1 ))) dmu0y = 2.0 * ( dT * tyi . reshape (( - 1 , 1 ))) dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( ( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy [:, n_sum_categories :] += np . diag ( muxy_vec2 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , )","title":"IPFP solvers"},{"location":"ipfp_solvers/#ipfp_solvers-module","text":"Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the Choo and Siow 2006 <https://www.jstor.org/stable/10.1086/498585?seq=1> _ model: homoskedastic with singles (as in Choo and Siow 2006) homoskedastic without singles gender-heteroskedastic: with a scale parameter on the error term for women gender- and type-heteroskedastic: with a scale parameter on the error term for each gender and type two-level nested logit, with nests and nest parameters that do not depend on the type, and {0} as the first nest Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using gr=True ) the derivatives of the matching patterns in all primitives.","title":"ipfp_solvers module"},{"location":"ipfp_solvers/#bs_cupid_try.ipfp_solvers.ipfp_gender_heteroskedastic_solver","text":"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter tau Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tau float the standard error for all women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, tau) if gr is True Source code in bs_cupid_try/ipfp_solvers.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 def ipfp_gender_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tau : float , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter `tau` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tau: the standard error for all women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if tau <= 0 : bs_error_abort ( f \"We need a positive tau, not { tau } \" ) ############################################################################# # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau ############################################################################# sigma_x = np . ones ( X ) tau_y = np . full ( Y , tau ) if gr : ( mus_hxy , marg_err_x , marg_err_y , dmus_xy , dmus_x0 , dmus_0y , ) = ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = True , maxiter = maxiter , verbose = verbose , ) muxy , _ , _ , _ , _ = mus_hxy . unpack () n_sum_categories = X + Y n_prod_categories = X * Y n_cols = n_sum_categories + n_prod_categories itau_y = n_cols + X dmuxy = np . zeros (( n_prod_categories , n_cols + 1 )) dmuxy [:, : n_cols ] = dmus_xy [:, : n_cols ] dmuxy [:, - 1 ] = np . sum ( dmus_xy [:, itau_y :], 1 ) dmux0 = np . zeros (( X , n_cols + 1 )) dmux0 [:, : n_cols ] = dmus_x0 [:, : n_cols ] dmux0 [:, - 1 ] = np . sum ( dmus_x0 [:, itau_y :], 1 ) dmu0y = np . zeros (( Y , n_cols + 1 )) dmu0y [:, : n_cols ] = dmus_0y [:, : n_cols ] dmu0y [:, - 1 ] = np . sum ( dmus_0y [:, itau_y :], 1 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , ) else : return ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = False , maxiter = maxiter , verbose = verbose , )","title":"ipfp_gender_heteroskedastic_solver()"},{"location":"ipfp_solvers/#bs_cupid_try.ipfp_solvers.ipfp_heteroskedastic_solver","text":"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors sigma_x and tau_y Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required sigma_x np . ndarray the vector of standard errors for the X types of men required sigma_x np . ndarray the vector of standard errors for Y types of women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, sigma_x, tau_y) IPFPNoGradientResults | IPFPGradientResults if gr is True Source code in bs_cupid_try/ipfp_solvers.py 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 def ipfp_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , sigma_x : np . ndarray , tau_y : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors `sigma_x` and `tau_y` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) sigma_x: the vector of standard errors for the X types of men sigma_x: the vector of standard errors for Y types of women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if np . min ( sigma_x ) <= 0.0 : bs_error_abort ( \"All elements of sigma_x must be positive\" ) if np . min ( tau_y ) <= 0.0 : bs_error_abort ( \"All elements of tau_y must be positive\" ) sumxy1 = 1.0 / np . add . outer ( sigma_x , tau_y ) ephi2 , der_ephi2 = npexp ( Phi * sumxy1 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # with tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi2 )) # we find the largest values of sigma_x and tau_y xmax = np . argmax ( sigma_x ) sigma_max = sigma_x [ xmax ] ymax = np . argmax ( tau_y ) tau_max = tau_y [ ymax ] # we use tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) sig_taumax = sigma_x + tau_max txi = np . power ( bigc , sigma_x / sig_taumax ) sigmax_tau = tau_y + sigma_max tyi = np . power ( bigc , tau_y / sigmax_tau ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc txin = txi . copy () mu0y_in = np . power ( np . power ( tyi , sigmax_tau ), 1.0 / tau_y ) while err_newton > tol_newton : txit = np . power ( txin , sig_taumax ) mux0_in = np . power ( txit , 1.0 / sigma_x ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y ) ) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) errxi = mux0_in + np . sum ( muxy_in , 1 ) - men_margins err_newton = npmaxabs ( errxi ) txin -= errxi / ( sig_taumax * ( mux0_in / sigma_x + np . sum ( sumxy1 * muxy_in , 1 )) / txin ) tx = txin # Newton iterates for women err_newton = bigc tyin = tyi . copy () mux0_in = np . power ( np . power ( tx , sig_taumax ), 1.0 / sigma_x ) while err_newton > tol_newton : tyit = np . power ( tyin , sigmax_tau ) mu0y_in = np . power ( tyit , 1.0 / tau_y ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y ) ) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) erryi = mu0y_in + np . sum ( muxy_in , 0 ) - women_margins err_newton = npmaxabs ( erryi ) tyin -= erryi / ( sigmax_tau * ( mu0y_in / tau_y + np . sum ( sumxy1 * muxy_in , 0 )) / tyin ) ty = tyin err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = mux0_in mu0y = mu0y_in muxy = muxy_in marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute the derivatives n_sum_categories = X + Y n_prod_categories = X * Y # we work directly with (mux0, mu0y) sigrat_xy = sumxy1 * sigma_x . reshape (( - 1 , 1 )) taurat_xy = 1.0 - sigrat_xy mux0_mat = nprepeat_col ( mux0 , Y ) mu0y_mat = nprepeat_row ( mu0y , X ) # muxy = axy * bxy * ephi2 axy = nppow ( mux0_mat , sigrat_xy ) bxy = nppow ( mu0y_mat , taurat_xy ) der_axy1 , der_axy2 = der_nppow ( mux0_mat , sigrat_xy ) der_bxy1 , der_bxy2 = der_nppow ( mu0y_mat , taurat_xy ) der_axy1_rat , der_axy2_rat = der_axy1 / axy , der_axy2 / axy der_bxy1_rat , der_bxy2_rat = der_bxy1 / bxy , der_bxy2 / bxy # start with the LHS of the linear system on (dmux0, dmu0y) lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 1.0 + np . sum ( muxy * der_axy1_rat , 1 )) lhs [: X , X :] = muxy * der_bxy1_rat lhs [ X :, X :] = np . diag ( 1.0 + np . sum ( muxy * der_bxy1_rat , 0 )) lhs [ X :, : X ] = ( muxy * der_axy1_rat ) . T # now fill the RHS (derivatives wrt men_margins, then men_margins, # then Phi, then sigma_x and tau_y) n_cols_rhs = n_sum_categories + n_prod_categories + X + Y rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (mux0, mu0y) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (mux0, mu0y) wrt women_margins rhs [ X :, X : n_sum_categories ] = np . eye ( Y ) # the next line is sumxy1 with safeguards sumxy1_safe = sumxy1 * der_ephi2 / ephi2 big_a = muxy * sumxy1_safe big_b = der_axy2_rat - der_bxy2_rat b_mu_s = big_b * muxy * sumxy1 a_phi = Phi * big_a big_c = sumxy1 * ( a_phi - b_mu_s * tau_y ) big_d = sumxy1 * ( a_phi + b_mu_s * sigma_x . reshape (( - 1 , 1 ))) # to compute derivatives of (mux0, mu0y) wrt Phi ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - big_a [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories iend_phi = n_sum_categories + n_prod_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : iend_phi : Y ] = - big_a [:, iwoman ] ivar1 += 1 ivar2 += 1 # to compute derivatives of (mux0, mu0y) wrt sigma_x iend_sig = iend_phi + X der_sigx = np . sum ( big_c , 1 ) rhs [: X , iend_phi : iend_sig ] = np . diag ( der_sigx ) rhs [ X :, iend_phi : iend_sig ] = big_c . T # to compute derivatives of (mux0, mu0y) wrt tau_y der_tauy = np . sum ( big_d , 0 ) rhs [ X :, iend_sig :] = np . diag ( der_tauy ) rhs [: X , iend_sig :] = big_d # solve for the derivatives of mux0 and mu0y dmu0 = spla . solve ( lhs , rhs ) dmux0 = dmu0 [: X , :] dmu0y = dmu0 [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) der1 = ephi2 * der_axy1 * bxy ivar = 0 for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( der1 [ iman , :], dmux0 [ iman , :] ) ivar += Y der2 = ephi2 * der_bxy1 * axy for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( der2 [:, iwoman ], dmu0y [ iwoman , :] ) # add the terms that comes from differentiating ephi2 # on the derivative wrt Phi i = 0 j = n_sum_categories for iman in range ( X ): for iwoman in range ( Y ): dmuxy [ i , j ] += big_a [ iman , iwoman ] i += 1 j += 1 # on the derivative wrt sigma_x ivar = 0 ix = iend_phi for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), ix ] -= big_c [ iman , :] ivar += Y ix += 1 # on the derivative wrt tau_y iy = iend_sig for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , iy ] -= big_d [:, iwoman ] iy += 1 return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , )","title":"ipfp_heteroskedastic_solver()"},{"location":"ipfp_solvers/#bs_cupid_try.ipfp_solvers.ipfp_homoskedastic_nosingles_solver","text":"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Name Type Description muxy ThreeArrays | FourArrays the matching patterns, shape (X, Y) ThreeArrays | FourArrays marg_err_x, marg_err_y: the errors on the margins ThreeArrays | FourArrays and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if gr is True Source code in bs_cupid_try/ipfp_solvers.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def ipfp_homoskedastic_nosingles_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> ThreeArrays | FourArrays : \"\"\"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of $(\\mu_{xy})$ wrt $\\Phi$ verbose: if `True`, prints information maxiter: maximum number of iterations Returns: muxy: the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\mu_{xy})$ wrt $\\Phi$ if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) n_couples = np . sum ( men_margins ) # check that there are as many men as women if np . abs ( np . sum ( women_margins ) - n_couples ) > n_couples * tol : bs_error_abort ( \"There should be as many men as women\" ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ephi2T = ephi2 . T ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # starting with a reasonable initial point for tx and ty: : tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# bigc = sqrt ( n_couples / np . sum ( ephi2 )) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * err_diff niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = men_margins / sx sy = ephi2T @ tx ty = women_margins / sy err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi , tyi = tx , ty niter += 1 muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = np . sum ( muxy , 1 ) - men_margins marg_err_y = np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return muxy , marg_err_x , marg_err_y else : sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = 0 for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = 0 for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = ( - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ) ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( ( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy += np . diag ( muxy_vec2 ) return muxy , marg_err_x , marg_err_y , dmuxy","title":"ipfp_homoskedastic_nosingles_solver()"},{"location":"ipfp_solvers/#bs_cupid_try.ipfp_solvers.ipfp_homoskedastic_solver","text":"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) IPFPNoGradientResults | IPFPGradientResults if gr is True Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu , sigma = 0.0 , 1.0 n_bases = 4 bases_surplus = np . zeros (( X , Y , n_bases )) x_men = ( np . arange ( X ) - X / 2.0 ) / X y_women = ( np . arange ( Y ) - Y / 2.0 ) / Y bases_surplus [:, :, 0 ] = 1 for iy in range ( Y ): bases_surplus [:, iy , 1 ] = x_men for ix in range ( X ): bases_surplus [ ix , :, 2 ] = y_women for ix in range ( X ): for iy in range ( Y ): bases_surplus [ ix , iy , 3 ] = ( x_men [ ix ] - y_women [ iy ]) * ( x_men [ ix ] - y_women [ iy ] ) men_margins = np . random . uniform ( 1.0 , 10.0 , size = X ) women_margins = np . random . uniform ( 1.0 , 10.0 , size = Y ) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np . array ([ 3.0 , - 1.0 , - 1.0 , - 2.0 ]) true_surplus_matrix = bases_surplus @ true_surplus_params mus , marg_err_x , marg_err_y = ipfp_homoskedastic_solver ( true_surplus_matrix , men_margins , women_margins , tol = 1e-12 ) Source code in bs_cupid_try/ipfp_solvers.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 def ipfp_homoskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if `gr` is `True` Example: ```py # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu, sigma = 0.0, 1.0 n_bases = 4 bases_surplus = np.zeros((X, Y, n_bases)) x_men = (np.arange(X) - X / 2.0) / X y_women = (np.arange(Y) - Y / 2.0) / Y bases_surplus[:, :, 0] = 1 for iy in range(Y): bases_surplus[:, iy, 1] = x_men for ix in range(X): bases_surplus[ix, :, 2] = y_women for ix in range(X): for iy in range(Y): bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * ( x_men[ix] - y_women[iy] ) men_margins = np.random.uniform(1.0, 10.0, size=X) women_margins = np.random.uniform(1.0, 10.0, size=Y) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0]) true_surplus_matrix = bases_surplus @ true_surplus_params mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver( true_surplus_matrix, men_margins, women_margins, tol=1e-12 ) ``` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = True ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # where mux0=tx**2 and mu0y=ty**2 # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# ephi2T = ephi2 . T nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = sqrt ( nindivs / ( X + Y + 2.0 * np . sum ( ephi2 ))) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * bigc niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = ( np . sqrt ( sx * sx + 4.0 * men_margins ) - sx ) / 2.0 sy = ephi2T @ tx ty = ( np . sqrt ( sy * sy + 4.0 * women_margins ) - sy ) / 2.0 err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = txi * txi mu0y = tyi * tyi muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute the derivatives sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 2.0 * txi + sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( 2.0 * tyi + syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_sum_categories + n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute derivatives of (txi, tyi) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute derivatives of (txi, tyi) wrt women_margins rhs [ X : n_sum_categories , X : n_sum_categories ] = np . eye ( Y ) # to compute derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = ( - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ) ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of the mus dmux0 = 2.0 * ( dt * txi . reshape (( - 1 , 1 ))) dmu0y = 2.0 * ( dT * tyi . reshape (( - 1 , 1 ))) dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( ( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy [:, n_sum_categories :] += np . diag ( muxy_vec2 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , )","title":"ipfp_homoskedastic_solver()"},{"location":"matching_utils/","text":"matching_utils module \u00b6 matching-related utilities MatchingFunctionParam = Callable [[ Matching , list [ Any ]], np . ndarray ] module-attribute \u00b6 Same with a list of additional parameters Matching dataclass \u00b6 stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles Source code in bs_cupid_try/matching_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass class Matching : \"\"\"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles \"\"\" mux0 : np . ndarray = field ( init = False ) mu0y : np . ndarray = field ( init = False ) muxy : np . ndarray n : np . ndarray m : np . ndarray def __str__ ( self ): X , Y = self . muxy . shape n_couples = np . sum ( self . muxy ) n_men , n_women = np . sum ( self . n ), np . sum ( self . m ) repr_str = ( f \"This is a matching with { n_men } men, { n_women } single women. \\n \" ) repr_str += f \" with { n_couples } couples, \\n \\n \" repr_str += f \" We have { X } types of men and { Y } of women.\" print_stars ( repr_str ) def __post_init__ ( self ): X , Y = test_matrix ( self . muxy ) Xn = test_vector ( self . n ) Ym = test_vector ( self . m ) if Xn != X : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) self . mux0 , self . mu0y = _get_singles ( self . muxy , self . n , self . m ) def unpack ( self ): return self . muxy , self . mux0 , self . mu0y , self . n , self . m","title":"Utilities for Matching"},{"location":"matching_utils/#matching_utils-module","text":"matching-related utilities","title":"matching_utils module"},{"location":"matching_utils/#bs_cupid_try.matching_utils.MatchingFunctionParam","text":"Same with a list of additional parameters","title":"MatchingFunctionParam"},{"location":"matching_utils/#bs_cupid_try.matching_utils.Matching","text":"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles Source code in bs_cupid_try/matching_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @dataclass class Matching : \"\"\"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles \"\"\" mux0 : np . ndarray = field ( init = False ) mu0y : np . ndarray = field ( init = False ) muxy : np . ndarray n : np . ndarray m : np . ndarray def __str__ ( self ): X , Y = self . muxy . shape n_couples = np . sum ( self . muxy ) n_men , n_women = np . sum ( self . n ), np . sum ( self . m ) repr_str = ( f \"This is a matching with { n_men } men, { n_women } single women. \\n \" ) repr_str += f \" with { n_couples } couples, \\n \\n \" repr_str += f \" We have { X } types of men and { Y } of women.\" print_stars ( repr_str ) def __post_init__ ( self ): X , Y = test_matrix ( self . muxy ) Xn = test_vector ( self . n ) Ym = test_vector ( self . m ) if Xn != X : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) self . mux0 , self . mu0y = _get_singles ( self . muxy , self . n , self . m ) def unpack ( self ): return self . muxy , self . mux0 , self . mu0y , self . n , self . m","title":"Matching"},{"location":"min_distance/","text":"min_distance module \u00b6 Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters. estimate_semilinear_mde ( muhat , phi_bases , entropy , additional_parameters = None , initial_weights = None ) \u00b6 Estimates the parameters of the distributions and of the base functions. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required entropy EntropyFunctions an EntropyFunctions object required additional_parameters Optional [ list ] additional parameters of the distribution of errors, if any None initial_weights Optional [ np . ndarray ] if specified, used as the weighting matrix for the first step when entropy.param_dependent is True None Returns: Type Description MDEResults an MDEResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 X , Y , K = 10 , 20 , 2 n_households = int ( 1e6 ) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np . ones ( n_alpha ) true_coeffs = np . concatenate (( true_alpha , lambda_true )) print_stars ( entropy_model . description ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_model , additional_parameters = additional_parameters ) mde_results . print_results ( true_coeffs = true_coeffs , n_alpha = 1 ) Source code in bs_cupid_try/min_distance.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 def estimate_semilinear_mde ( muhat : Matching , phi_bases : np . ndarray , entropy : EntropyFunctions , additional_parameters : Optional [ list ] = None , initial_weights : Optional [ np . ndarray ] = None , ) -> MDEResults : \"\"\" Estimates the parameters of the distributions and of the base functions. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases entropy: an `EntropyFunctions` object additional_parameters: additional parameters of the distribution of errors, if any initial_weights: if specified, used as the weighting matrix for the first step when `entropy.param_dependent` is `True` Returns: an `MDEResults` instance Example: ```py X, Y, K = 10, 20, 2 n_households = int(1e6) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) n = np.ones(X) m = np.ones(Y) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) choo_siow_instance.describe() muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np.ones(n_alpha) true_coeffs = np.concatenate((true_alpha, lambda_true)) print_stars(entropy_model.description) mde_results = estimate_semilinear_mde( mus_sim, phi_bases, entropy_model, additional_parameters=additional_parameters ) mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1) ``` \"\"\" muxyhat , _ , _ , nhat , mhat = muhat . unpack () X , Y = muxyhat . shape XY = X * Y ndims_phi = phi_bases . ndim if ndims_phi != 3 : bs_error_abort ( f \"phi_bases should have 3 dimensions, not { ndims_phi } \" ) Xp , Yp , K = phi_bases . shape if Xp != X or Yp != Y : bs_error_abort ( f \"phi_bases should have shape ( { X } , { Y } , { K } ) not ( { Xp } , { Yp } , { K } )\" ) parameterized_entropy = entropy . parameter_dependent if parameterized_entropy : if initial_weights is None : print_stars ( \"Using the identity matrix as weighting matrix in the first step.\" ) S_mat = np . eye ( XY ) else : S_mat = initial_weights phi_mat = _make_XY_K_mat ( phi_bases ) e0_fun = entropy . e0_fun if additional_parameters is None : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) else : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) e0_hat = e0_vals . ravel () if not parameterized_entropy : # we only have e0(mu,r) n_pars = K hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) if additional_parameters is None : hessian_components_mumu = e0_derivative [ 0 ]( muhat ) hessian_components_mur = e0_derivative [ 1 ]( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) hessian_components_mumu = e0_derivative1 [ 0 ]( muhat , additional_parameters ) hessian_components_mur = e0_derivative1 [ 1 ]( muhat , additional_parameters ) else : if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat ) else : hessian_components = _numeric_hessian ( entropy , muhat , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) estimated_coefficients , varcov_coefficients = _compute_estimates ( phi_mat , S_mat , e0_hat ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ estimated_coefficients residuals = est_Phi + e0_hat else : # parameterized entropy: e0(mu,r) + e(mu,r) . alpha # create the F matrix if additional_parameters is None : e_fun = cast ( MatchingFunction , entropy . e_fun ) e_vals = e_fun ( muhat ) else : e_fun1 = cast ( MatchingFunctionParam , entropy . e_fun ) e_vals = e_fun1 ( muhat , additional_parameters ) e_hat = _make_XY_K_mat ( e_vals ) F_hat = np . column_stack (( e_hat , phi_mat )) n_pars = e_hat . shape [ 1 ] + K # first pass with an initial weighting matrix first_coeffs , _ = _compute_estimates ( F_hat , S_mat , e0_hat ) first_alpha = first_coeffs [: - K ] # compute the efficient weighting matrix hessian = entropy . hessian if hessian == \"provided\" : if additional_parameters is None : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) e_derivative = cast ( EntropyHessians , entropy . e_derivative ) e0_derivative_mumu = cast ( EntropyHessianMuMu , e0_derivative [ 0 ] ) hessian_components_mumu_e0 = e0_derivative_mumu ( muhat ) e0_derivative_mur = cast ( EntropyHessianMuR , e0_derivative [ 1 ]) hessian_components_mur_e0 = e0_derivative_mur ( muhat ) e_derivative_mumu = cast ( EntropyHessianMuMu , e_derivative [ 0 ]) hessian_components_mumu_e = e_derivative_mumu ( muhat ) e_derivative_mur = cast ( EntropyHessianMuR , e_derivative [ 1 ]) hessian_components_mur_e = e_derivative_mur ( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) e_derivative1 = cast ( EntropyHessiansParam , entropy . e_derivative ) e0_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e0_derivative1 [ 0 ] ) e0_derivative_mur1 = cast ( EntropyHessianMuRParam , e0_derivative1 [ 1 ] ) e_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e_derivative1 [ 0 ] ) e_derivative_mur1 = cast ( EntropyHessianMuRParam , e_derivative1 [ 1 ] ) hessian_components_mumu_e0 = e0_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e0 = e0_derivative_mur1 ( muhat , additional_parameters ) hessian_components_mumu_e = e_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e = e_derivative_mur1 ( muhat , additional_parameters ) # print_stars(\"First-stage estimates:\") # print(first_coeffs) hessian_components_mumu1 = ( hessian_components_mumu_e0 [ 0 ] + hessian_components_mumu_e [ 0 ] @ first_alpha , hessian_components_mumu_e0 [ 1 ] + hessian_components_mumu_e [ 1 ] @ first_alpha , hessian_components_mumu_e0 [ 2 ] + hessian_components_mumu_e [ 2 ] @ first_alpha , ) hessian_components_mur1 = ( hessian_components_mur_e0 [ 0 ] + hessian_components_mur_e [ 0 ] @ first_alpha , hessian_components_mur_e0 [ 1 ] + hessian_components_mur_e [ 1 ] @ first_alpha , ) hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu1 ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur1 ) else : # numeric hessian if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha ) else : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) # second pass estimated_coefficients , varcov_coefficients = _compute_estimates ( F_hat , S_mat , e0_hat ) est_alpha , est_beta = ( estimated_coefficients [: - K ], estimated_coefficients [ - K :], ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ est_beta residuals = est_Phi + e0_hat + e_hat @ est_alpha value_obj = residuals . T @ S_mat @ residuals ndf = X * Y - n_pars test_stat = value_obj n_individuals = np . sum ( nhat ) + np . sum ( mhat ) n_households = n_individuals - np . sum ( muxyhat ) results = MDEResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_coefficients = estimated_coefficients , varcov_coefficients = varcov_coefficients , stderrs_coefficients = stderrs_coefficients , estimated_Phi = est_Phi . reshape (( X , Y )), test_statistic = test_stat , ndf = ndf , test_pvalue = sts . chi2 . sf ( test_stat , ndf ), parameterized_entropy = parameterized_entropy , ) return results","title":"MDE estimator"},{"location":"min_distance/#min_distance-module","text":"Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters.","title":"min_distance module"},{"location":"min_distance/#bs_cupid_try.min_distance.estimate_semilinear_mde","text":"Estimates the parameters of the distributions and of the base functions. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required entropy EntropyFunctions an EntropyFunctions object required additional_parameters Optional [ list ] additional parameters of the distribution of errors, if any None initial_weights Optional [ np . ndarray ] if specified, used as the weighting matrix for the first step when entropy.param_dependent is True None Returns: Type Description MDEResults an MDEResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 X , Y , K = 10 , 20 , 2 n_households = int ( 1e6 ) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np . ones ( n_alpha ) true_coeffs = np . concatenate (( true_alpha , lambda_true )) print_stars ( entropy_model . description ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_model , additional_parameters = additional_parameters ) mde_results . print_results ( true_coeffs = true_coeffs , n_alpha = 1 ) Source code in bs_cupid_try/min_distance.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 def estimate_semilinear_mde ( muhat : Matching , phi_bases : np . ndarray , entropy : EntropyFunctions , additional_parameters : Optional [ list ] = None , initial_weights : Optional [ np . ndarray ] = None , ) -> MDEResults : \"\"\" Estimates the parameters of the distributions and of the base functions. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases entropy: an `EntropyFunctions` object additional_parameters: additional parameters of the distribution of errors, if any initial_weights: if specified, used as the weighting matrix for the first step when `entropy.param_dependent` is `True` Returns: an `MDEResults` instance Example: ```py X, Y, K = 10, 20, 2 n_households = int(1e6) # we simulate a Choo and Siow population # with equal numbers of men and women of each type lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) n = np.ones(X) m = np.ones(Y) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) choo_siow_instance.describe() muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np.ones(n_alpha) true_coeffs = np.concatenate((true_alpha, lambda_true)) print_stars(entropy_model.description) mde_results = estimate_semilinear_mde( mus_sim, phi_bases, entropy_model, additional_parameters=additional_parameters ) mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1) ``` \"\"\" muxyhat , _ , _ , nhat , mhat = muhat . unpack () X , Y = muxyhat . shape XY = X * Y ndims_phi = phi_bases . ndim if ndims_phi != 3 : bs_error_abort ( f \"phi_bases should have 3 dimensions, not { ndims_phi } \" ) Xp , Yp , K = phi_bases . shape if Xp != X or Yp != Y : bs_error_abort ( f \"phi_bases should have shape ( { X } , { Y } , { K } ) not ( { Xp } , { Yp } , { K } )\" ) parameterized_entropy = entropy . parameter_dependent if parameterized_entropy : if initial_weights is None : print_stars ( \"Using the identity matrix as weighting matrix in the first step.\" ) S_mat = np . eye ( XY ) else : S_mat = initial_weights phi_mat = _make_XY_K_mat ( phi_bases ) e0_fun = entropy . e0_fun if additional_parameters is None : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) else : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) e0_hat = e0_vals . ravel () if not parameterized_entropy : # we only have e0(mu,r) n_pars = K hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) if additional_parameters is None : hessian_components_mumu = e0_derivative [ 0 ]( muhat ) hessian_components_mur = e0_derivative [ 1 ]( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) hessian_components_mumu = e0_derivative1 [ 0 ]( muhat , additional_parameters ) hessian_components_mur = e0_derivative1 [ 1 ]( muhat , additional_parameters ) else : if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat ) else : hessian_components = _numeric_hessian ( entropy , muhat , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) estimated_coefficients , varcov_coefficients = _compute_estimates ( phi_mat , S_mat , e0_hat ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ estimated_coefficients residuals = est_Phi + e0_hat else : # parameterized entropy: e0(mu,r) + e(mu,r) . alpha # create the F matrix if additional_parameters is None : e_fun = cast ( MatchingFunction , entropy . e_fun ) e_vals = e_fun ( muhat ) else : e_fun1 = cast ( MatchingFunctionParam , entropy . e_fun ) e_vals = e_fun1 ( muhat , additional_parameters ) e_hat = _make_XY_K_mat ( e_vals ) F_hat = np . column_stack (( e_hat , phi_mat )) n_pars = e_hat . shape [ 1 ] + K # first pass with an initial weighting matrix first_coeffs , _ = _compute_estimates ( F_hat , S_mat , e0_hat ) first_alpha = first_coeffs [: - K ] # compute the efficient weighting matrix hessian = entropy . hessian if hessian == \"provided\" : if additional_parameters is None : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) e_derivative = cast ( EntropyHessians , entropy . e_derivative ) e0_derivative_mumu = cast ( EntropyHessianMuMu , e0_derivative [ 0 ] ) hessian_components_mumu_e0 = e0_derivative_mumu ( muhat ) e0_derivative_mur = cast ( EntropyHessianMuR , e0_derivative [ 1 ]) hessian_components_mur_e0 = e0_derivative_mur ( muhat ) e_derivative_mumu = cast ( EntropyHessianMuMu , e_derivative [ 0 ]) hessian_components_mumu_e = e_derivative_mumu ( muhat ) e_derivative_mur = cast ( EntropyHessianMuR , e_derivative [ 1 ]) hessian_components_mur_e = e_derivative_mur ( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) e_derivative1 = cast ( EntropyHessiansParam , entropy . e_derivative ) e0_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e0_derivative1 [ 0 ] ) e0_derivative_mur1 = cast ( EntropyHessianMuRParam , e0_derivative1 [ 1 ] ) e_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e_derivative1 [ 0 ] ) e_derivative_mur1 = cast ( EntropyHessianMuRParam , e_derivative1 [ 1 ] ) hessian_components_mumu_e0 = e0_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e0 = e0_derivative_mur1 ( muhat , additional_parameters ) hessian_components_mumu_e = e_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e = e_derivative_mur1 ( muhat , additional_parameters ) # print_stars(\"First-stage estimates:\") # print(first_coeffs) hessian_components_mumu1 = ( hessian_components_mumu_e0 [ 0 ] + hessian_components_mumu_e [ 0 ] @ first_alpha , hessian_components_mumu_e0 [ 1 ] + hessian_components_mumu_e [ 1 ] @ first_alpha , hessian_components_mumu_e0 [ 2 ] + hessian_components_mumu_e [ 2 ] @ first_alpha , ) hessian_components_mur1 = ( hessian_components_mur_e0 [ 0 ] + hessian_components_mur_e [ 0 ] @ first_alpha , hessian_components_mur_e0 [ 1 ] + hessian_components_mur_e [ 1 ] @ first_alpha , ) hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu1 ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur1 ) else : # numeric hessian if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha ) else : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) _ , var_munm = _variance_muhat ( muhat ) var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) # second pass estimated_coefficients , varcov_coefficients = _compute_estimates ( F_hat , S_mat , e0_hat ) est_alpha , est_beta = ( estimated_coefficients [: - K ], estimated_coefficients [ - K :], ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ est_beta residuals = est_Phi + e0_hat + e_hat @ est_alpha value_obj = residuals . T @ S_mat @ residuals ndf = X * Y - n_pars test_stat = value_obj n_individuals = np . sum ( nhat ) + np . sum ( mhat ) n_households = n_individuals - np . sum ( muxyhat ) results = MDEResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_coefficients = estimated_coefficients , varcov_coefficients = varcov_coefficients , stderrs_coefficients = stderrs_coefficients , estimated_Phi = est_Phi . reshape (( X , Y )), test_statistic = test_stat , ndf = ndf , test_pvalue = sts . chi2 . sf ( test_stat , ndf ), parameterized_entropy = parameterized_entropy , ) return results","title":"estimate_semilinear_mde()"},{"location":"min_distance_utils/","text":"min_distance_utils module \u00b6 Utility programs used in min_distance.py . MDEResults dataclass \u00b6 The results from minimum-distance estimation and testing. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required estimated_coefficients np . ndarray np.ndarray required varcov_coefficients np . ndarray np.ndarray required stderrs_coefficients np . ndarray np.ndarray required estimated_Phi np . ndarray np.ndarray required test_statistic float float required test_pvalue float float required ndf int int required parameterized_entropy Optional [ bool ] Optional[bool] = False False Source code in bs_cupid_try/min_distance_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 @dataclass class MDEResults : \"\"\" The results from minimum-distance estimation and testing. Args: X: int Y: int K: int number_households: int estimated_coefficients: np.ndarray varcov_coefficients: np.ndarray stderrs_coefficients: np.ndarray estimated_Phi: np.ndarray test_statistic: float test_pvalue: float ndf: int parameterized_entropy: Optional[bool] = False \"\"\" X : int Y : int K : int number_households : int estimated_coefficients : np . ndarray varcov_coefficients : np . ndarray stderrs_coefficients : np . ndarray estimated_Phi : np . ndarray test_statistic : float test_pvalue : float ndf : int parameterized_entropy : Optional [ bool ] = False def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" if self . parameterized_entropy : n_alpha = self . estimated_coefficients . size - self . K entropy_str = f \" The entropy has { n_alpha } parameters.\" else : entropy_str = \" The entropy is parameter-free.\" n_alpha = 0 model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += ( f \"The model has { self . X } x { self . Y } margins \\n { entropy_str } \\n \" ) model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += ( \"The estimated coefficients (and their standard errors) are \\n\\n \" ) if self . parameterized_entropy : for i , coeff in enumerate ( self . estimated_coefficients [: n_alpha ]): repr_str += ( f \" alpha( { i + 1 } ): { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ i ] : .3f } ) \\n \" ) repr_str += \" \\n \" for i , coeff in enumerate ( self . estimated_coefficients [ n_alpha :]): repr_str += ( f \" base { i + 1 } : { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ n_alpha + i ] : .3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += f \" the value of the test statistic is { self . test_statistic : > 10.3f } \\n \" repr_str += f \" for a chi2( { self . ndf } ), the p-value is { self . test_pvalue : > 10.3f } \\n \" return repr_str + line_stars def print_results ( self , true_coeffs : Optional [ np . ndarray ] = None , n_alpha : int = 0 ) -> None | float : estimates = self . estimated_coefficients stderrs = self . stderrs_coefficients if true_coeffs is not None : repr_str = ( \"The true and estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str += f \" alpha( { i + 1 } ): { true_coeffs [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += ( f \" base { i + 1 } : { true_coeffs [ j ] : > 10.3f } \" + f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) discrepancy = npmaxabs ( true_coeffs - estimates ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) else : repr_str = ( \"The estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str + f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" repr_str += \" \\n Specification test: \\n \" repr_str += ( \" the value of the test statistic is \" + f \" { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), \" + f \"the p-value is { self . test_pvalue : > 10.3f } \\n \" ) print_stars ( repr_str ) if true_coeffs is not None : return discrepancy return None","title":"Utilities for MDE"},{"location":"min_distance_utils/#min_distance_utils-module","text":"Utility programs used in min_distance.py .","title":"min_distance_utils module"},{"location":"min_distance_utils/#bs_cupid_try.min_distance_utils.MDEResults","text":"The results from minimum-distance estimation and testing. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required estimated_coefficients np . ndarray np.ndarray required varcov_coefficients np . ndarray np.ndarray required stderrs_coefficients np . ndarray np.ndarray required estimated_Phi np . ndarray np.ndarray required test_statistic float float required test_pvalue float float required ndf int int required parameterized_entropy Optional [ bool ] Optional[bool] = False False Source code in bs_cupid_try/min_distance_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 @dataclass class MDEResults : \"\"\" The results from minimum-distance estimation and testing. Args: X: int Y: int K: int number_households: int estimated_coefficients: np.ndarray varcov_coefficients: np.ndarray stderrs_coefficients: np.ndarray estimated_Phi: np.ndarray test_statistic: float test_pvalue: float ndf: int parameterized_entropy: Optional[bool] = False \"\"\" X : int Y : int K : int number_households : int estimated_coefficients : np . ndarray varcov_coefficients : np . ndarray stderrs_coefficients : np . ndarray estimated_Phi : np . ndarray test_statistic : float test_pvalue : float ndf : int parameterized_entropy : Optional [ bool ] = False def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" if self . parameterized_entropy : n_alpha = self . estimated_coefficients . size - self . K entropy_str = f \" The entropy has { n_alpha } parameters.\" else : entropy_str = \" The entropy is parameter-free.\" n_alpha = 0 model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += ( f \"The model has { self . X } x { self . Y } margins \\n { entropy_str } \\n \" ) model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += ( \"The estimated coefficients (and their standard errors) are \\n\\n \" ) if self . parameterized_entropy : for i , coeff in enumerate ( self . estimated_coefficients [: n_alpha ]): repr_str += ( f \" alpha( { i + 1 } ): { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ i ] : .3f } ) \\n \" ) repr_str += \" \\n \" for i , coeff in enumerate ( self . estimated_coefficients [ n_alpha :]): repr_str += ( f \" base { i + 1 } : { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ n_alpha + i ] : .3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += f \" the value of the test statistic is { self . test_statistic : > 10.3f } \\n \" repr_str += f \" for a chi2( { self . ndf } ), the p-value is { self . test_pvalue : > 10.3f } \\n \" return repr_str + line_stars def print_results ( self , true_coeffs : Optional [ np . ndarray ] = None , n_alpha : int = 0 ) -> None | float : estimates = self . estimated_coefficients stderrs = self . stderrs_coefficients if true_coeffs is not None : repr_str = ( \"The true and estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str += f \" alpha( { i + 1 } ): { true_coeffs [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += ( f \" base { i + 1 } : { true_coeffs [ j ] : > 10.3f } \" + f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) discrepancy = npmaxabs ( true_coeffs - estimates ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) else : repr_str = ( \"The estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str + f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" repr_str += \" \\n Specification test: \\n \" repr_str += ( \" the value of the test statistic is \" + f \" { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), \" + f \"the p-value is { self . test_pvalue : > 10.3f } \\n \" ) print_stars ( repr_str ) if true_coeffs is not None : return discrepancy return None","title":"MDEResults"},{"location":"model_classes/","text":"model_classes module \u00b6 NestedLogitPrimitives dataclass \u00b6 Source code in bs_cupid_try/model_classes.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 @dataclass class NestedLogitPrimitives : Phi : np . ndarray n : np . ndarray m : np . ndarray nests_for_each_x : NestsList # given by user, e.g. [[1, 3], [2,4]] has y=1 and y=3 in first nest nests_for_each_y : NestsList nests_over_Y : NestsList # rebased to zero: the above example becomes [[0, 2], [1,3]] nests_over_X : NestsList i_nest_of_x : Nest # mapping x -> n' i_nest_of_y : Nest # mapping y -> n n_alphas : int mus : Optional [ Matching ] = None true_alphas : Optional [ np . ndarray ] = None def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : Optional [ np . ndarray ] = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = test_matrix ( Phi ) Xn = test_vector ( n ) Ym = test_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = test_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist () def __str__ ( self ): X , Y = self . Phi . shape nmen , nwomen = np . sum ( self . n ), np . sum ( self . m ) repr_str = ( f \"This is a 2-level nested logit with { nmen } men of { X } types\" + f \" and { nwomen } women of { Y } types. \\n \" ) repr_str += ( f \" We have { self . n_nests_over_Y } nests over 1...Y \" + f \" and { self . n_nests_over_X } nests over 1...X, \\n \" ) if self . true_alphas is None : repr_str += \" with unspecified nests parameters.\" else : alpha_vals = self . true_alphas repr_str += \" with respective nests parameters: \\n \" repr_str += f \" { alpha_vals [: self . n_nests_over_Y ] } \\n \" repr_str += f \" and { alpha_vals [ self . n_nests_over_Y :] } \\n \" print_stars ( repr_str ) def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = ( 1e-4 * bigc ) # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y )) ) n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y def ipfp_solve ( self ) -> Matching : if self . true_alphas is None : bs_error_abort ( \"true_alphas must be specified to solve the nested logit by IPFP.\" ) self . mus , err_x , err_y = self . ipfp_nested_logit_solver ( verbose = False ) return self . mus def simulate ( self , n_households : int , seed : Optional [ int ] = None ) -> Matching : self . mus = self . ipfp_solve () mus_sim = _simulate_sample_from_mus ( self . mus , n_households , seed ) return mus_sim __init__ ( Phi , n , m , nests_for_each_x , nests_for_each_y , true_alphas = None ) \u00b6 We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Parameters: Name Type Description Default Phi np . ndarray the (X,Y) joint surplus matrix required n np . ndarray the X-vector of men margins required m np . ndarray the X-vector of women margins required nests_for_each_x NestsList the composition of the nests over 1...Y, a list of r lists required nests_for_each_y NestsList the composition of the nests over 1...X, a list of d lists required true_alphas Optional [ np . ndarray ] the true nest parameters, if any; should be an (r+d)-vector None Source code in bs_cupid_try/model_classes.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : Optional [ np . ndarray ] = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = test_matrix ( Phi ) Xn = test_vector ( n ) Ym = test_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = test_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist () ipfp_nested_logit_solver ( tol = 1e-09 , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns Parameters: Name Type Description Default tol float tolerance on change in solution 1e-09 verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description Matching the matching patterns np . ndarray marg_err_x, marg_err_y: the errors on the margins Source code in bs_cupid_try/model_classes.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = ( 1e-4 * bigc ) # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y )) ) n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y","title":"Classes used"},{"location":"model_classes/#model_classes-module","text":"","title":"model_classes module"},{"location":"model_classes/#bs_cupid_try.model_classes.NestedLogitPrimitives","text":"Source code in bs_cupid_try/model_classes.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 @dataclass class NestedLogitPrimitives : Phi : np . ndarray n : np . ndarray m : np . ndarray nests_for_each_x : NestsList # given by user, e.g. [[1, 3], [2,4]] has y=1 and y=3 in first nest nests_for_each_y : NestsList nests_over_Y : NestsList # rebased to zero: the above example becomes [[0, 2], [1,3]] nests_over_X : NestsList i_nest_of_x : Nest # mapping x -> n' i_nest_of_y : Nest # mapping y -> n n_alphas : int mus : Optional [ Matching ] = None true_alphas : Optional [ np . ndarray ] = None def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : Optional [ np . ndarray ] = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = test_matrix ( Phi ) Xn = test_vector ( n ) Ym = test_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = test_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist () def __str__ ( self ): X , Y = self . Phi . shape nmen , nwomen = np . sum ( self . n ), np . sum ( self . m ) repr_str = ( f \"This is a 2-level nested logit with { nmen } men of { X } types\" + f \" and { nwomen } women of { Y } types. \\n \" ) repr_str += ( f \" We have { self . n_nests_over_Y } nests over 1...Y \" + f \" and { self . n_nests_over_X } nests over 1...X, \\n \" ) if self . true_alphas is None : repr_str += \" with unspecified nests parameters.\" else : alpha_vals = self . true_alphas repr_str += \" with respective nests parameters: \\n \" repr_str += f \" { alpha_vals [: self . n_nests_over_Y ] } \\n \" repr_str += f \" and { alpha_vals [ self . n_nests_over_Y :] } \\n \" print_stars ( repr_str ) def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = ( 1e-4 * bigc ) # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y )) ) n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y def ipfp_solve ( self ) -> Matching : if self . true_alphas is None : bs_error_abort ( \"true_alphas must be specified to solve the nested logit by IPFP.\" ) self . mus , err_x , err_y = self . ipfp_nested_logit_solver ( verbose = False ) return self . mus def simulate ( self , n_households : int , seed : Optional [ int ] = None ) -> Matching : self . mus = self . ipfp_solve () mus_sim = _simulate_sample_from_mus ( self . mus , n_households , seed ) return mus_sim","title":"NestedLogitPrimitives"},{"location":"model_classes/#bs_cupid_try.model_classes.NestedLogitPrimitives.__init__","text":"We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Parameters: Name Type Description Default Phi np . ndarray the (X,Y) joint surplus matrix required n np . ndarray the X-vector of men margins required m np . ndarray the X-vector of women margins required nests_for_each_x NestsList the composition of the nests over 1...Y, a list of r lists required nests_for_each_y NestsList the composition of the nests over 1...X, a list of d lists required true_alphas Optional [ np . ndarray ] the true nest parameters, if any; should be an (r+d)-vector None Source code in bs_cupid_try/model_classes.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : Optional [ np . ndarray ] = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = test_matrix ( Phi ) Xn = test_vector ( n ) Ym = test_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = test_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist ()","title":"__init__()"},{"location":"model_classes/#bs_cupid_try.model_classes.NestedLogitPrimitives.ipfp_nested_logit_solver","text":"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns Parameters: Name Type Description Default tol float tolerance on change in solution 1e-09 verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description Matching the matching patterns np . ndarray marg_err_x, marg_err_y: the errors on the margins Source code in bs_cupid_try/model_classes.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = ( 1e-4 * bigc ) # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y )) ) n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = _compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y","title":"ipfp_nested_logit_solver()"},{"location":"nested_logit/","text":"nested_logit module \u00b6 The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters. e0_derivative_mu_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/nested_logit.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def e0_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) der_logxn = 1.0 / mu_xn for y in nest : hess_x [ x , y , :] = - dlogx0 hess_x [ x , y , nest ] -= der_logxn for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) der_logny = 1.0 / mu_ny for x in nest : hess_y [ x , y , :] = - dlog0y hess_y [ x , y , nest ] -= der_logny for x in range ( X ): for y in range ( Y ): hess_xy [ x , y ] = hess_x [ x , y , y ] + hess_y [ x , y , x ] return hess_x , hess_y , hess_xy e0_derivative_r_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/nested_logit.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def e0_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : for y in nest : hess_n [ x , y ] = dlogx0 for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : for x in nest : hess_m [ x , y ] = dlog0y return hess_n , hess_m e0_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the values of the parameter-independent part $e_0$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/nested_logit.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def e0_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape e0_vals = np . zeros (( X , Y )) for x in range ( X ): mux0_x = mux0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) e0_vals [ x , nest ] = - log ( mu_xn / mux0_x ) for y in range ( Y ): mu0y_y = mu0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) e0_vals [ nest , y ] -= log ( mu_ny / mu0y_y ) return e0_vals e_derivative_mu_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/nested_logit.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def e_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) der_logxn = 1.0 / mu_xn for t in nest : hess_x [ x , nest , t , i_n ] = der_logxn hess_xy [ x , nest , i_n ] = der_logxn - der_logxy [ x , nest ] for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) der_logny = 1.0 / mu_ny i_n2 = i_n + n_rhos for z in nest : hess_y [ nest , y , z , i_n2 ] = der_logny hess_xy [ nest , y , i_n2 ] = der_logny - der_logxy [ nest , y ] return hess_x , hess_y , hess_xy e_derivative_r_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/nested_logit.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 def e_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) return hess_n , hess_m e_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the values of the parameter-dependent part $e$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y,n_alpha) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/nested_logit.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def e_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape e_vals = np . zeros (( X , Y , n_alpha )) for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) e_vals [ x , nest , i_n ] = - np . log ( mux_nest_n / mu_xn ) for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) e_vals [ nest , y , ( i_n + n_rhos )] -= np . log ( muy_nest_n / mu_ny ) return e_vals","title":"Nested Logit"},{"location":"nested_logit/#nested_logit-module","text":"The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.","title":"nested_logit module"},{"location":"nested_logit/#bs_cupid_try.nested_logit.e0_derivative_mu_nested_logit","text":"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/nested_logit.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def e0_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) der_logxn = 1.0 / mu_xn for y in nest : hess_x [ x , y , :] = - dlogx0 hess_x [ x , y , nest ] -= der_logxn for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) der_logny = 1.0 / mu_ny for x in nest : hess_y [ x , y , :] = - dlog0y hess_y [ x , y , nest ] -= der_logny for x in range ( X ): for y in range ( Y ): hess_xy [ x , y ] = hess_x [ x , y , y ] + hess_y [ x , y , x ] return hess_x , hess_y , hess_xy","title":"e0_derivative_mu_nested_logit()"},{"location":"nested_logit/#bs_cupid_try.nested_logit.e0_derivative_r_nested_logit","text":"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/nested_logit.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def e0_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : for y in nest : hess_n [ x , y ] = dlogx0 for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : for x in nest : hess_m [ x , y ] = dlog0y return hess_n , hess_m","title":"e0_derivative_r_nested_logit()"},{"location":"nested_logit/#bs_cupid_try.nested_logit.e0_nested_logit","text":"Returns the values of the parameter-independent part $e_0$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/nested_logit.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def e0_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape e0_vals = np . zeros (( X , Y )) for x in range ( X ): mux0_x = mux0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) e0_vals [ x , nest ] = - log ( mu_xn / mux0_x ) for y in range ( Y ): mu0y_y = mu0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) e0_vals [ nest , y ] -= log ( mu_ny / mu0y_y ) return e0_vals","title":"e0_nested_logit()"},{"location":"nested_logit/#bs_cupid_try.nested_logit.e_derivative_mu_nested_logit","text":"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt $(\\mu,\\mu)$. Source code in bs_cupid_try/nested_logit.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def e_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) der_logxn = 1.0 / mu_xn for t in nest : hess_x [ x , nest , t , i_n ] = der_logxn hess_xy [ x , nest , i_n ] = der_logxn - der_logxy [ x , nest ] for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) der_logny = 1.0 / mu_ny i_n2 = i_n + n_rhos for z in nest : hess_y [ nest , y , z , i_n2 ] = der_logny hess_xy [ nest , y , i_n2 ] = der_logny - der_logxy [ nest , y ] return hess_x , hess_y , hess_xy","title":"e_derivative_mu_nested_logit()"},{"location":"nested_logit/#bs_cupid_try.nested_logit.e_derivative_r_nested_logit","text":"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt $(\\mu,r)$. Source code in bs_cupid_try/nested_logit.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 def e_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) return hess_n , hess_m","title":"e_derivative_r_nested_logit()"},{"location":"nested_logit/#bs_cupid_try.nested_logit.e_nested_logit","text":"Returns the values of the parameter-dependent part $e$ for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y,n_alpha) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in bs_cupid_try/nested_logit.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def e_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape e_vals = np . zeros (( X , Y , n_alpha )) for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) e_vals [ x , nest , i_n ] = - np . log ( mux_nest_n / mu_xn ) for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) e_vals [ nest , y , ( i_n + n_rhos )] -= np . log ( muy_nest_n / mu_ny ) return e_vals","title":"e_nested_logit()"},{"location":"poisson_glm/","text":"poisson_glm module \u00b6 Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. choo_siow_poisson_glm ( muhat , phi_bases , tol = 1e-12 , max_iter = 10000 , verbose = 1 ) \u00b6 Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required tol Optional [ float ] tolerance level for linear_model.PoissonRegressor.fit 1e-12 max_iter Optional [ int ] maximum number of iterations for linear_model.PoissonRegressor.fit 10000 verbose Optional [ int ] defines how much output we want (0 = least) 1 Returns: Type Description PoissonGLMResults a PoissonGLMResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 n_households = 1e6 X , Y , K = 4 , 3 , 6 # we setup a quadratic set of basis functions phi_bases = np . zeros (( X , Y , K )) phi_bases [:, :, 0 ] = 1 for x in range ( X ): phi_bases [ x , :, 1 ] = x phi_bases [ x , :, 3 ] = x * x for y in range ( Y ): phi_bases [ x , y , 4 ] = x * y for y in range ( Y ): phi_bases [:, y , 2 ] = y phi_bases [:, y , 5 ] = y * y lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np . ones ( X ) m = np . ones ( Y ) choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () results = choo_siow_poisson_glm ( mus_sim , phi_bases ) # compare true and estimated parameters results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) ) Source code in bs_cupid_try/poisson_glm.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def choo_siow_poisson_glm ( muhat : Matching , phi_bases : np . ndarray , tol : Optional [ float ] = 1e-12 , max_iter : Optional [ int ] = 10000 , verbose : Optional [ int ] = 1 , ) -> PoissonGLMResults : \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases tol: tolerance level for `linear_model.PoissonRegressor.fit` max_iter: maximum number of iterations for `linear_model.PoissonRegressor.fit` verbose: defines how much output we want (0 = least) Returns: a `PoissonGLMResults` instance Example: ```py n_households = 1e6 X, Y, K = 4, 3, 6 # we setup a quadratic set of basis functions phi_bases = np.zeros((X, Y, K)) phi_bases[:, :, 0] = 1 for x in range(X): phi_bases[x, :, 1] = x phi_bases[x, :, 3] = x * x for y in range(Y): phi_bases[x, y, 4] = x * y for y in range(Y): phi_bases[:, y, 2] = y phi_bases[:, y, 5] = y * y lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np.ones(X) m = np.ones(Y) choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() results = choo_siow_poisson_glm(mus_sim, phi_bases) # compare true and estimated parameters results.print_results( lambda_true, u_true=-np.log(mux0_sim / n_sim), v_true=-np.log(mu0y_sim / m_sim) ) ``` \"\"\" try_sparse = False X , Y , K = phi_bases . shape XY = X * Y n_rows = XY + X + Y n_cols = X + Y + K # the vector of weights for the Poisson regression w = np . concatenate (( 2 * np . ones ( XY ), np . ones ( X + Y ))) # reshape the bases phi_mat = _make_XY_K_mat ( phi_bases ) if try_sparse : w_mat = spr . csr_matrix ( np . concatenate ( ( 2 * np . ones (( XY , n_cols )), np . ones (( X + Y , n_cols ))) ) ) # construct the Z matrix ones_X = spr . csr_matrix ( np . ones (( X , 1 ))) ones_Y = spr . csr_matrix ( np . ones (( Y , 1 ))) zeros_XK = spr . csr_matrix ( np . zeros (( X , K ))) zeros_YK = spr . csr_matrix ( np . zeros (( Y , K ))) zeros_XY = spr . csr_matrix ( np . zeros (( X , Y ))) zeros_YX = spr . csr_matrix ( np . zeros (( Y , X ))) id_X = spr . csr_matrix ( np . eye ( X )) id_Y = spr . csr_matrix ( np . eye ( Y )) Z_unweighted = spr . vstack ( [ spr . hstack ( [ - spr . kron ( id_X , ones_Y ), - spr . kron ( ones_X , id_Y ), phi_mat , ] ), spr . hstack ([ - id_X , zeros_XY , zeros_XK ]), spr . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w_mat else : ones_X = np . ones (( X , 1 )) ones_Y = np . ones (( Y , 1 )) zeros_XK = np . zeros (( X , K )) zeros_YK = np . zeros (( Y , K )) zeros_XY = np . zeros (( X , Y )) zeros_YX = np . zeros (( Y , X )) id_X = np . eye ( X ) id_Y = np . eye ( Y ) Z_unweighted = np . vstack ( [ np . hstack ( [ - np . kron ( id_X , ones_Y ), - np . kron ( ones_X , id_Y ), phi_mat ] ), np . hstack ([ - id_X , zeros_XY , zeros_XK ]), np . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w . reshape (( - 1 , 1 )) _ , _ , _ , n , m = muhat . unpack () var_muhat , var_munm = _variance_muhat ( muhat ) ( muxyhat_norm , var_muhat_norm , var_munm_norm , n_households , n_individuals , ) = _prepare_data ( muhat , var_muhat , var_munm ) clf = linear_model . PoissonRegressor ( fit_intercept = False , tol = tol , verbose = verbose , alpha = 0 , max_iter = max_iter , ) clf . fit ( Z , muxyhat_norm , sample_weight = w ) gamma_est = clf . coef_ # we compute the variance-covariance of the estimator nr , nc = Z . shape exp_Zg = np . exp ( Z @ gamma_est ) . reshape ( n_rows ) A_hat = np . zeros (( nc , nc )) B_hat = np . zeros (( nc , nc )) for i in range ( nr ): Zi = Z [ i , :] wi = w [ i ] A_hat += wi * exp_Zg [ i ] * np . outer ( Zi , Zi ) for j in range ( nr ): Zj = Z [ j , :] B_hat += wi * w [ j ] * var_muhat_norm [ i , j ] * np . outer ( Zi , Zj ) A_inv = spla . inv ( A_hat ) varcov_gamma = A_inv @ B_hat @ A_inv stderrs_gamma = np . sqrt ( np . diag ( varcov_gamma )) beta_est = gamma_est [ - K :] varcov_beta = varcov_gamma [ - K :, - K :] beta_std = stderrs_gamma [ - K :] Phi_est = phi_bases @ beta_est # we correct for the effect of the normalization n_norm = n / n_individuals m_norm = m / n_individuals u_est = gamma_est [: X ] + np . log ( n_norm ) v_est = gamma_est [ X : - K ] + np . log ( m_norm ) # since u = a + log(n_norm) we also need to adjust the estimated variance z_unweighted_T = Z_unweighted . T u_std = np . zeros ( X ) ix = XY for x in range ( X ): n_norm_x = n_norm [ x ] A_inv_x = A_inv [ x , :] var_log_nx = var_munm_norm [ ix , ix ] / n_norm_x / n_norm_x slice_x = slice ( x * Y , ( x + 1 ) * Y ) covar_term = var_muhat_norm [:, ix ] + np . sum ( var_muhat_norm [:, slice_x ], 1 ) cov_a_lognx = ( A_inv_x @ z_unweighted_T @ covar_term ) / n_norm_x ux_var = varcov_gamma [ x , x ] + var_log_nx + 2.0 * cov_a_lognx u_std [ x ] = sqrt ( ux_var ) ix += 1 v_std = stderrs_gamma [ X : - K ] iy , jy = X , XY + X for y in range ( Y ): m_norm_y = m_norm [ y ] A_inv_y = A_inv [ iy , :] var_log_my = var_munm_norm [ jy , jy ] / m_norm_y / m_norm_y slice_y = slice ( y , XY , Y ) covar_term = var_muhat_norm [:, jy ] + np . sum ( var_muhat_norm [:, slice_y ], 1 ) cov_b_logmy = ( A_inv_y @ z_unweighted_T @ covar_term ) / m_norm_y vy_var = varcov_gamma [ iy , iy ] + var_log_my + 2.0 * cov_b_logmy v_std [ y ] = sqrt ( vy_var ) iy += 1 jy += 1 results = PoissonGLMResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_gamma = gamma_est , estimated_Phi = Phi_est , estimated_beta = beta_est , estimated_u = u_est , estimated_v = v_est , varcov_gamma = varcov_gamma , varcov_beta = varcov_beta , stderrs_gamma = stderrs_gamma , stderrs_beta = beta_std , stderrs_u = u_std , stderrs_v = v_std , ) return results","title":"Poisson estimator"},{"location":"poisson_glm/#poisson_glm-module","text":"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM.","title":"poisson_glm module"},{"location":"poisson_glm/#bs_cupid_try.poisson_glm.choo_siow_poisson_glm","text":"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required tol Optional [ float ] tolerance level for linear_model.PoissonRegressor.fit 1e-12 max_iter Optional [ int ] maximum number of iterations for linear_model.PoissonRegressor.fit 10000 verbose Optional [ int ] defines how much output we want (0 = least) 1 Returns: Type Description PoissonGLMResults a PoissonGLMResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 n_households = 1e6 X , Y , K = 4 , 3 , 6 # we setup a quadratic set of basis functions phi_bases = np . zeros (( X , Y , K )) phi_bases [:, :, 0 ] = 1 for x in range ( X ): phi_bases [ x , :, 1 ] = x phi_bases [ x , :, 3 ] = x * x for y in range ( Y ): phi_bases [ x , y , 4 ] = x * y for y in range ( Y ): phi_bases [:, y , 2 ] = y phi_bases [:, y , 5 ] = y * y lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np . ones ( X ) m = np . ones ( Y ) choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () results = choo_siow_poisson_glm ( mus_sim , phi_bases ) # compare true and estimated parameters results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) ) Source code in bs_cupid_try/poisson_glm.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def choo_siow_poisson_glm ( muhat : Matching , phi_bases : np . ndarray , tol : Optional [ float ] = 1e-12 , max_iter : Optional [ int ] = 10000 , verbose : Optional [ int ] = 1 , ) -> PoissonGLMResults : \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases tol: tolerance level for `linear_model.PoissonRegressor.fit` max_iter: maximum number of iterations for `linear_model.PoissonRegressor.fit` verbose: defines how much output we want (0 = least) Returns: a `PoissonGLMResults` instance Example: ```py n_households = 1e6 X, Y, K = 4, 3, 6 # we setup a quadratic set of basis functions phi_bases = np.zeros((X, Y, K)) phi_bases[:, :, 0] = 1 for x in range(X): phi_bases[x, :, 1] = x phi_bases[x, :, 3] = x * x for y in range(Y): phi_bases[x, y, 4] = x * y for y in range(Y): phi_bases[:, y, 2] = y phi_bases[:, y, 5] = y * y lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np.ones(X) m = np.ones(Y) choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() results = choo_siow_poisson_glm(mus_sim, phi_bases) # compare true and estimated parameters results.print_results( lambda_true, u_true=-np.log(mux0_sim / n_sim), v_true=-np.log(mu0y_sim / m_sim) ) ``` \"\"\" try_sparse = False X , Y , K = phi_bases . shape XY = X * Y n_rows = XY + X + Y n_cols = X + Y + K # the vector of weights for the Poisson regression w = np . concatenate (( 2 * np . ones ( XY ), np . ones ( X + Y ))) # reshape the bases phi_mat = _make_XY_K_mat ( phi_bases ) if try_sparse : w_mat = spr . csr_matrix ( np . concatenate ( ( 2 * np . ones (( XY , n_cols )), np . ones (( X + Y , n_cols ))) ) ) # construct the Z matrix ones_X = spr . csr_matrix ( np . ones (( X , 1 ))) ones_Y = spr . csr_matrix ( np . ones (( Y , 1 ))) zeros_XK = spr . csr_matrix ( np . zeros (( X , K ))) zeros_YK = spr . csr_matrix ( np . zeros (( Y , K ))) zeros_XY = spr . csr_matrix ( np . zeros (( X , Y ))) zeros_YX = spr . csr_matrix ( np . zeros (( Y , X ))) id_X = spr . csr_matrix ( np . eye ( X )) id_Y = spr . csr_matrix ( np . eye ( Y )) Z_unweighted = spr . vstack ( [ spr . hstack ( [ - spr . kron ( id_X , ones_Y ), - spr . kron ( ones_X , id_Y ), phi_mat , ] ), spr . hstack ([ - id_X , zeros_XY , zeros_XK ]), spr . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w_mat else : ones_X = np . ones (( X , 1 )) ones_Y = np . ones (( Y , 1 )) zeros_XK = np . zeros (( X , K )) zeros_YK = np . zeros (( Y , K )) zeros_XY = np . zeros (( X , Y )) zeros_YX = np . zeros (( Y , X )) id_X = np . eye ( X ) id_Y = np . eye ( Y ) Z_unweighted = np . vstack ( [ np . hstack ( [ - np . kron ( id_X , ones_Y ), - np . kron ( ones_X , id_Y ), phi_mat ] ), np . hstack ([ - id_X , zeros_XY , zeros_XK ]), np . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w . reshape (( - 1 , 1 )) _ , _ , _ , n , m = muhat . unpack () var_muhat , var_munm = _variance_muhat ( muhat ) ( muxyhat_norm , var_muhat_norm , var_munm_norm , n_households , n_individuals , ) = _prepare_data ( muhat , var_muhat , var_munm ) clf = linear_model . PoissonRegressor ( fit_intercept = False , tol = tol , verbose = verbose , alpha = 0 , max_iter = max_iter , ) clf . fit ( Z , muxyhat_norm , sample_weight = w ) gamma_est = clf . coef_ # we compute the variance-covariance of the estimator nr , nc = Z . shape exp_Zg = np . exp ( Z @ gamma_est ) . reshape ( n_rows ) A_hat = np . zeros (( nc , nc )) B_hat = np . zeros (( nc , nc )) for i in range ( nr ): Zi = Z [ i , :] wi = w [ i ] A_hat += wi * exp_Zg [ i ] * np . outer ( Zi , Zi ) for j in range ( nr ): Zj = Z [ j , :] B_hat += wi * w [ j ] * var_muhat_norm [ i , j ] * np . outer ( Zi , Zj ) A_inv = spla . inv ( A_hat ) varcov_gamma = A_inv @ B_hat @ A_inv stderrs_gamma = np . sqrt ( np . diag ( varcov_gamma )) beta_est = gamma_est [ - K :] varcov_beta = varcov_gamma [ - K :, - K :] beta_std = stderrs_gamma [ - K :] Phi_est = phi_bases @ beta_est # we correct for the effect of the normalization n_norm = n / n_individuals m_norm = m / n_individuals u_est = gamma_est [: X ] + np . log ( n_norm ) v_est = gamma_est [ X : - K ] + np . log ( m_norm ) # since u = a + log(n_norm) we also need to adjust the estimated variance z_unweighted_T = Z_unweighted . T u_std = np . zeros ( X ) ix = XY for x in range ( X ): n_norm_x = n_norm [ x ] A_inv_x = A_inv [ x , :] var_log_nx = var_munm_norm [ ix , ix ] / n_norm_x / n_norm_x slice_x = slice ( x * Y , ( x + 1 ) * Y ) covar_term = var_muhat_norm [:, ix ] + np . sum ( var_muhat_norm [:, slice_x ], 1 ) cov_a_lognx = ( A_inv_x @ z_unweighted_T @ covar_term ) / n_norm_x ux_var = varcov_gamma [ x , x ] + var_log_nx + 2.0 * cov_a_lognx u_std [ x ] = sqrt ( ux_var ) ix += 1 v_std = stderrs_gamma [ X : - K ] iy , jy = X , XY + X for y in range ( Y ): m_norm_y = m_norm [ y ] A_inv_y = A_inv [ iy , :] var_log_my = var_munm_norm [ jy , jy ] / m_norm_y / m_norm_y slice_y = slice ( y , XY , Y ) covar_term = var_muhat_norm [:, jy ] + np . sum ( var_muhat_norm [:, slice_y ], 1 ) cov_b_logmy = ( A_inv_y @ z_unweighted_T @ covar_term ) / m_norm_y vy_var = varcov_gamma [ iy , iy ] + var_log_my + 2.0 * cov_b_logmy v_std [ y ] = sqrt ( vy_var ) iy += 1 jy += 1 results = PoissonGLMResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_gamma = gamma_est , estimated_Phi = Phi_est , estimated_beta = beta_est , estimated_u = u_est , estimated_v = v_est , varcov_gamma = varcov_gamma , varcov_beta = varcov_beta , stderrs_gamma = stderrs_gamma , stderrs_beta = beta_std , stderrs_u = u_std , stderrs_v = v_std , ) return results","title":"choo_siow_poisson_glm()"},{"location":"poisson_glm_utils/","text":"poisson_glm_utils module \u00b6 Utilities for Poisson GLM. PoissonGLMResults dataclass \u00b6 Stores and formats the estimation results. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required number_individuals int int required estimated_gamma np . ndarray np.ndarray required varcov_gamma np . ndarray np.ndarray required stderrs_gamma np . ndarray np.ndarray required estimated_beta np . ndarray np.ndarray required estimated_u np . ndarray np.ndarray required estimated_v np . ndarray np.ndarray required varcov_beta np . ndarray np.ndarray required stderrs_beta np . ndarray np.ndarray required stderrs_u np . ndarray np.ndarray required stderrs_v np . ndarray np.ndarray required estimated_Phi np . ndarray np.ndarray required Source code in bs_cupid_try/poisson_glm_utils.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 @dataclass class PoissonGLMResults : \"\"\"Stores and formats the estimation results. Args: X: int Y: int K: int number_households: int number_individuals: int estimated_gamma: np.ndarray varcov_gamma: np.ndarray stderrs_gamma: np.ndarray estimated_beta: np.ndarray estimated_u: np.ndarray estimated_v: np.ndarray varcov_beta: np.ndarray stderrs_beta: np.ndarray stderrs_u: np.ndarray stderrs_v: np.ndarray estimated_Phi: np.ndarray \"\"\" X : int Y : int K : int number_households : int number_individuals : int estimated_gamma : np . ndarray varcov_gamma : np . ndarray stderrs_gamma : np . ndarray estimated_beta : np . ndarray varcov_beta : np . ndarray estimated_u : np . ndarray estimated_v : np . ndarray stderrs_beta : np . ndarray stderrs_u : np . ndarray stderrs_v : np . ndarray estimated_Phi : np . ndarray def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" print_stars ( \"Estimating a Choo and Siow model by Poisson GLM.\" ) model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += \"The estimated basis coefficients (and their standard errors) are \\n\\n \" for i in range ( self . K ): repr_str += ( f \" base_ { i + 1 } : { self . estimated_beta [ i ] : > 10.3f } \" + f \"( { self . stderrs_beta [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of men (and their standard errors) are \\n\\n \" for i in range ( self . X ): repr_str += ( f \" u_ { i + 1 } : { self . estimated_u [ i ] : > 10.3f } \" + f \"( { self . stderrs_u [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of women (and their standard errors) are \\n\\n \" for i in range ( self . Y ): repr_str += ( f \" v { i + 1 } : { self . estimated_v [ i ] : > 10.3f } \" + f \"( { self . stderrs_v [ i ] : .3f } ) \\n \" ) return repr_str + line_stars def print_results ( self , lambda_true : Optional [ np . ndarray ] = None , u_true : Optional [ np . ndarray ] = None , v_true : Optional [ np . ndarray ] = None , ) -> float | None : estimates_beta = self . estimated_beta stderrs_beta = self . stderrs_beta if lambda_true is None : repr_str = \"The estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += ( f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) else : repr_str = \"The true and estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" base { i + 1 } : { lambda_true [ i ] : > 10.3f } \" repr_str += ( f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) estimates_u = self . estimated_u stderrs_u = self . stderrs_u if u_true is None : repr_str = \"The estimated utilities for men \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for men\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" u_ { i + 1 } : { u_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) estimates_v = self . estimated_v stderrs_v = self . stderrs_v if v_true is None : repr_str = \"The estimated utilities for women \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for women\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" v_ { i + 1 } : { v_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) if lambda_true is None : return None else : discrepancy = npmaxabs ( lambda_true - estimates_beta ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) return discrepancy","title":"Utilities for Poisson"},{"location":"poisson_glm_utils/#poisson_glm_utils-module","text":"Utilities for Poisson GLM.","title":"poisson_glm_utils module"},{"location":"poisson_glm_utils/#bs_cupid_try.poisson_glm_utils.PoissonGLMResults","text":"Stores and formats the estimation results. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required number_individuals int int required estimated_gamma np . ndarray np.ndarray required varcov_gamma np . ndarray np.ndarray required stderrs_gamma np . ndarray np.ndarray required estimated_beta np . ndarray np.ndarray required estimated_u np . ndarray np.ndarray required estimated_v np . ndarray np.ndarray required varcov_beta np . ndarray np.ndarray required stderrs_beta np . ndarray np.ndarray required stderrs_u np . ndarray np.ndarray required stderrs_v np . ndarray np.ndarray required estimated_Phi np . ndarray np.ndarray required Source code in bs_cupid_try/poisson_glm_utils.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 @dataclass class PoissonGLMResults : \"\"\"Stores and formats the estimation results. Args: X: int Y: int K: int number_households: int number_individuals: int estimated_gamma: np.ndarray varcov_gamma: np.ndarray stderrs_gamma: np.ndarray estimated_beta: np.ndarray estimated_u: np.ndarray estimated_v: np.ndarray varcov_beta: np.ndarray stderrs_beta: np.ndarray stderrs_u: np.ndarray stderrs_v: np.ndarray estimated_Phi: np.ndarray \"\"\" X : int Y : int K : int number_households : int number_individuals : int estimated_gamma : np . ndarray varcov_gamma : np . ndarray stderrs_gamma : np . ndarray estimated_beta : np . ndarray varcov_beta : np . ndarray estimated_u : np . ndarray estimated_v : np . ndarray stderrs_beta : np . ndarray stderrs_u : np . ndarray stderrs_v : np . ndarray estimated_Phi : np . ndarray def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" print_stars ( \"Estimating a Choo and Siow model by Poisson GLM.\" ) model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += \"The estimated basis coefficients (and their standard errors) are \\n\\n \" for i in range ( self . K ): repr_str += ( f \" base_ { i + 1 } : { self . estimated_beta [ i ] : > 10.3f } \" + f \"( { self . stderrs_beta [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of men (and their standard errors) are \\n\\n \" for i in range ( self . X ): repr_str += ( f \" u_ { i + 1 } : { self . estimated_u [ i ] : > 10.3f } \" + f \"( { self . stderrs_u [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of women (and their standard errors) are \\n\\n \" for i in range ( self . Y ): repr_str += ( f \" v { i + 1 } : { self . estimated_v [ i ] : > 10.3f } \" + f \"( { self . stderrs_v [ i ] : .3f } ) \\n \" ) return repr_str + line_stars def print_results ( self , lambda_true : Optional [ np . ndarray ] = None , u_true : Optional [ np . ndarray ] = None , v_true : Optional [ np . ndarray ] = None , ) -> float | None : estimates_beta = self . estimated_beta stderrs_beta = self . stderrs_beta if lambda_true is None : repr_str = \"The estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += ( f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) else : repr_str = \"The true and estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" base { i + 1 } : { lambda_true [ i ] : > 10.3f } \" repr_str += ( f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) estimates_u = self . estimated_u stderrs_u = self . stderrs_u if u_true is None : repr_str = \"The estimated utilities for men \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for men\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_u ): repr_str += f \" u_ { i + 1 } : { u_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_u [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) estimates_v = self . estimated_v stderrs_v = self . stderrs_v if v_true is None : repr_str = \"The estimated utilities for women \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated utilities for women\" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( estimates_v ): repr_str += f \" v_ { i + 1 } : { v_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_v [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) if lambda_true is None : return None else : discrepancy = npmaxabs ( lambda_true - estimates_beta ) print_stars ( f \"The true-estimated discrepancy is { discrepancy } \" ) return discrepancy","title":"PoissonGLMResults"},{"location":"utils/","text":"utils module \u00b6 This module contains some utility programs used by the package. ScalarFunctionAndGradient : TypeAlias = Callable [[ np . ndarray , list , Optional [ bool ]], float | tuple [ float , np . ndarray ]] module-attribute \u00b6 Type of f(v, args, gr) that returns a scalar value and also a gradient if gr is True bs_error_abort ( msg = 'error, aborting' ) \u00b6 Report error and exits with code 1 Parameters: Name Type Description Default msg str specifies the error message 'error, aborting' Returns: Type Description None nothing Source code in bs_cupid_try/utils.py 72 73 74 75 76 77 78 79 80 81 82 def bs_error_abort ( msg : str = \"error, aborting\" ) -> None : \"\"\"Report error and exits with code 1 Args: msg: specifies the error message Returns: nothing \"\"\" print_stars ( f \" { bs_name_func ( 3 ) } : { msg } \" ) sys . exit ( 1 ) bs_name_func ( back = 2 ) \u00b6 Get the name of the current function, or further back in the stack Parameters: Name Type Description Default back int 2 for the current function, 3 for the function that called it, etc 2 Returns: Type Description str the name of the function requested Source code in bs_cupid_try/utils.py 39 40 41 42 43 44 45 46 47 48 49 50 def bs_name_func ( back : int = 2 ) -> str : \"\"\"Get the name of the current function, or further back in the stack Args: back: 2 for the current function, 3 for the function that called it, etc Returns: the name of the function requested \"\"\" stack = extract_stack () func_name : str = stack [ - back ][ 2 ] return func_name check_gradient_scalar_function ( fg , p , args , mode = 'central' , EPS = 1e-06 ) \u00b6 Checks the gradient of a scalar function. Parameters: Name Type Description Default fg Any should return the scalar value, and the gradient if its gr argument is True required p np . ndarray where we are checking the gradient required args list [ Any ] other arguments passed to fg required mode str \"central\" or \"forward\" derivatives 'central' EPS float the step for forward or central derivatives 1e-06 Returns: Type Description tuple [ np . ndarray , np . ndarray ] the analytic and numeric gradients Source code in bs_cupid_try/utils.py 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 def check_gradient_scalar_function ( fg : Any , p : np . ndarray , args : list [ Any ], mode : str = \"central\" , EPS : float = 1e-6 , ) -> tuple [ np . ndarray , np . ndarray ]: \"\"\"Checks the gradient of a scalar function. Args: fg: should return the scalar value, and the gradient if its `gr` argument is `True` p: where we are checking the gradient args: other arguments passed to `fg` mode: \"central\" or \"forward\" derivatives EPS: the step for forward or central derivatives Returns: the analytic and numeric gradients \"\"\" # if not isinstance(fg, ScalarFunctionAndGradient): # bs_error_abort(\"wrong type for fg\") f0 , f_grad = fg ( p , args , True ) print_stars ( \"checking the gradient: analytic, numeric\" ) g = np . zeros_like ( p ) sp : int = p . size if mode == \"central\" : for i in range ( sp ): x = p [ i ] p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , False ) p1 [ i ] -= 2.0 * EPS f_minus = fg ( p1 , args , False ) g [ i ] = ( f_plus - f_minus ) / ( 2.0 * EPS ) print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) elif mode == \"forward\" : for i in range ( sp ): x = p [ i ] p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , False ) g [ i ] = ( f_plus - f0 ) / EPS print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) else : bs_error_abort ( \"mode must be 'central' or 'forward'\" ) return f_grad , g der_nppow ( a , b ) \u00b6 evaluates the derivatives in a and b of element-by-element $a^b$ Parameters: Name Type Description Default a np . ndarray input Numpy arrays required b int | float | np . ndarray a Numpy array of the same shape, or a scalar required Returns: Type Description TwoArrays a pair of two arrays of the same shape as a Source code in bs_cupid_try/utils.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def der_nppow ( a : np . ndarray , b : int | float | np . ndarray ) -> TwoArrays : \"\"\" evaluates the derivatives in a and b of element-by-element $a^b$ Args: a: input Numpy arrays b: a Numpy array of the same shape, or a scalar Returns: a pair of two arrays of the same shape as `a` \"\"\" mina : float = np . min ( a ) if mina <= 0 : print_stars ( \"All elements of a must be positive in der_nppow!\" ) sys . exit ( 1 ) if isinstance ( b , ( int , float )): a_pow_b = np . power ( a , b ) return ( b * a_pow_b / a , a_pow_b * log ( a )) else : if a . shape != b . shape : print_stars ( \"nppow: b is not a number or an array of the same shape as a!\" ) sys . exit ( 1 ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape ) describe_array ( v , name = 'The array' ) \u00b6 Descriptive statistics on an array interpreted as a vector Parameters: Name Type Description Default v np . ndarray the array required name str its name 'The array' Returns: Type Description NamedTuple a DescribeResult namedtuple Source code in bs_cupid_try/utils.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def describe_array ( v : np . ndarray , name : str = \"The array\" ) -> NamedTuple : \"\"\"Descriptive statistics on an array interpreted as a vector Args: v: the array name: its name Returns: a `DescribeResult` namedtuple \"\"\" print_stars ( f \" { name } has:\" ) d = sts . describe ( v , None ) print ( f \"Number of elements: { d . nobs } \" ) print ( f \"Minimum: { d . minmax [ 0 ] } \" ) print ( f \"Maximum: { d . minmax [ 1 ] } \" ) print ( f \"Mean: { d . mean } \" ) print ( f \"Stderr: { sqrt ( d . variance ) } \" ) return d npexp ( a , deriv = False , bigx = 30.0 , verbose = False ) \u00b6 $C^2$ extension of $\\exp(a)$ above bigx Parameters: Name Type Description Default a np . ndarray a Numpy array required deriv bool if True , the first derivative is also returned False bigx float an upper bound 30.0 verbose bool whether diagnoses are printed False Returns: Name Type Description bigx np . ndarray | TwoArrays upper bound $\\exp(a)$ $C^2$-extended above bigx , np . ndarray | TwoArrays with its derivative if deriv is True Source code in bs_cupid_try/utils.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 def npexp ( a : np . ndarray , deriv : bool = False , bigx : float = 30.0 , verbose : bool = False , ) -> np . ndarray | TwoArrays : \"\"\" $C^2$ extension of $\\exp(a)$ above `bigx` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned bigx: an upper bound verbose: whether diagnoses are printed Returns: bigx: upper bound $\\exp(a)$ $C^2$-extended above `bigx`, with its derivative if `deriv` is `True` \"\"\" if np . max ( a ) < bigx : expa = np . exp ( a ) return ( expa , expa ) if deriv else expa else : exparr = np . exp ( np . minimum ( a , bigx )) ebigx = exp ( bigx ) darr = a - bigx exparr_larger = ebigx * ( 1.0 + darr * ( 1.0 + 0.5 * darr )) if verbose : n_large_args = np . sum ( a > bigx ) if n_large_args > 0 : finals = \"s\" if n_large_args > 1 else \"\" print ( f \"npexp: { n_large_args } argument { finals } larger than { bigx } : maxi = { np . max ( a ) } \" ) expa = np . where ( a < bigx , exparr , exparr_larger ) if deriv : der_exparr = np . exp ( np . minimum ( a , bigx )) der_exparr_larger = ebigx * ( 1.0 + darr ) der_expa = np . where ( a < bigx , der_exparr , der_exparr_larger ) return expa , der_expa else : return expa nplog ( a , deriv = False , eps = 1e-30 , verbose = False ) \u00b6 $C^2$ extension of $\\ln(a)$ below eps Parameters: Name Type Description Default a np . ndarray a Numpy array required deriv bool if True , the first derivative is also returned False eps float a lower bound 1e-30 verbose bool whether diagnoses are printed False Returns: Type Description np . ndarray | tuple [ np . ndarray , np . ndarray ] $\\ln(a)$ $C^2$-extended below eps , np . ndarray | tuple [ np . ndarray , np . ndarray ] with its derivative if deriv is True Source code in bs_cupid_try/utils.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def nplog ( a : np . ndarray , deriv : bool = False , eps : float = 1e-30 , verbose : bool = False , ) -> np . ndarray | tuple [ np . ndarray , np . ndarray ]: \"\"\"$C^2$ extension of $\\ln(a)$ below `eps` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned eps: a lower bound verbose: whether diagnoses are printed Returns: $\\ln(a)$ $C^2$-extended below `eps`, with its derivative if `deriv` is `True` \"\"\" if np . min ( a ) > eps : loga = np . log ( a ) return ( loga , 1.0 / a ) if deriv else loga else : logarreps = np . log ( np . maximum ( a , eps )) logarr_smaller = log ( eps ) - ( eps - a ) * ( 3.0 * eps - a ) / ( 2.0 * eps * eps ) if verbose : n_small_args = np . sum ( a < eps ) if n_small_args > 0 : finals = \"s\" if n_small_args > 1 else \"\" print ( f \"nplog: { n_small_args } argument { finals } smaller than { eps } : mini = { np . min ( a ) } \" ) loga = np . where ( a > eps , logarreps , logarr_smaller ) if deriv : der_logarreps = 1.0 / np . maximum ( a , eps ) der_logarr_smaller = ( 2.0 * eps - a ) / ( eps * eps ) der_loga = np . where ( a > eps , der_logarreps , der_logarr_smaller ) return loga , der_loga else : return loga npmaxabs ( a ) \u00b6 The maximum absolute value in an array Parameters: Name Type Description Default a np . ndarray the array required Returns: Type Description float $\\max{ ert a ert}$ Source code in bs_cupid_try/utils.py 178 179 180 181 182 183 184 185 186 187 188 def npmaxabs ( a : np . ndarray ) -> float : \"\"\"The maximum absolute value in an array Args: a: the array Returns: $\\max{\\vert a \\vert}$ \"\"\" maxi : float = np . max ( np . abs ( a )) return maxi nppow ( a , b , deriv = False ) \u00b6 Evaluates $a^b$ element-by-element Parameters: Name Type Description Default a np . ndarray a Numpy array required b int | float | np . ndarray if an array, it should have the same shape as a required deriv bool if True , the first derivatives wrt a and b are also returned False Returns: Type Description np . ndarray | ThreeArrays an array of the same shape as a , and if deriv is True , np . ndarray | ThreeArrays the derivatives wrt a and b Source code in bs_cupid_try/utils.py 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 def nppow ( a : np . ndarray , b : int | float | np . ndarray , deriv : bool = False ) -> np . ndarray | ThreeArrays : \"\"\"Evaluates $a^b$ element-by-element Args: a: a Numpy array b: if an array, it should have the same shape as `a` deriv: if `True`, the first derivatives wrt `a` and `b` are also returned Returns: an array of the same shape as `a`, and if `deriv` is `True`, the derivatives wrt `a` and `b` \"\"\" mina = np . min ( a ) if mina <= 0 : bs_error_abort ( \"All elements of a must be positive!\" ) if isinstance ( b , ( int , float )): a_pow_b = a ** b if deriv : return ( a ** b , b * a_pow_b / a , a_pow_b * log ( a )) else : return a_pow_b else : if a . shape != b . shape : bs_error_abort ( f \"a has shape { a . shape } and b has shape { b . shape } \" ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec if deriv : der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return ( a_pow_b . reshape ( a . shape ), der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape ), ) else : return a_pow_b . reshape ( a . shape ) nprepeat_col ( v , n ) \u00b6 Creates a matrix with n columns, all equal to v Parameters: Name Type Description Default v np . ndarray a vector of size m required n int the number of columns requested required :return: a matrix of shape (m, n) Source code in bs_cupid_try/utils.py 149 150 151 152 153 154 155 156 157 158 159 160 def nprepeat_col ( v : np . ndarray , n : int ) -> np . ndarray : \"\"\"Creates a matrix with `n` columns, all equal to `v` Args: v: a vector of size `m` n: the number of columns requested :return: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_col\" ) w : np . ndarray = v [:, np . newaxis ] return np . repeat ( w , n , axis = 1 ) nprepeat_row ( v , m ) \u00b6 Creates a matrix with m rows, all equal to v Parameters: Name Type Description Default v np . ndarray a vector of size n required m int the number of rows requested required Returns: Type Description np . ndarray a matrix of shape (m, n) Source code in bs_cupid_try/utils.py 163 164 165 166 167 168 169 170 171 172 173 174 175 def nprepeat_row ( v : np . ndarray , m : int ) -> np . ndarray : \"\"\" Creates a matrix with `m` rows, all equal to `v` Args: v: a vector of size `n` m: the number of rows requested Returns: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_row\" ) return np . repeat ( v [ np . newaxis , :], m , axis = 0 ) print_stars ( title = None , n = 70 ) \u00b6 Prints a starred line, or two around the title Parameters: Name Type Description Default title Optional [ str ] an optional title None n int the number of stars on the line 70 Returns: Type Description None nothing Source code in bs_cupid_try/utils.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def print_stars ( title : Optional [ str ] = None , n : int = 70 ) -> None : \"\"\"Prints a starred line, or two around the title Args: title: an optional title n: the number of stars on the line Returns: nothing \"\"\" line_stars = \"*\" * n print () print ( line_stars ) if title : print ( title . center ( n )) print ( line_stars ) print () test_matrix ( x , fun_name = None ) \u00b6 Tests that x is a matrix; aborts otherwise Parameters: Name Type Description Default x Any a potential matrix required fun_name Optional [ str ] the name of the calling function None Returns: Type Description tuple [ int , int ] the shape of x if it is a matrix Source code in bs_cupid_try/utils.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def test_matrix ( x : Any , fun_name : Optional [ str ] = None ) -> tuple [ int , int ]: \"\"\"Tests that `x` is a matrix; aborts otherwise Args: x: a potential matrix fun_name: the name of the calling function Returns: the shape of `x` if it is a matrix \"\"\" fun_str : str = \"\" if fun_name is None else fun_name + \":\" if not isinstance ( x , np . ndarray ): bs_error_abort ( f \"x in { fun_str } should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 2 : bs_error_abort ( f \"x in { fun_str } should have two dimensions, not { ndims_x } \" ) shx : tuple [ int , int ] = x . shape return shx test_vector ( x , fun_name = None ) \u00b6 Tests that x is a vector; aborts otherwise Parameters: Name Type Description Default x Any a potential vector required fun_name Optional [ str ] the name of the calling function None Returns: Type Description int the size of x if it is a vector Source code in bs_cupid_try/utils.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def test_vector ( x : Any , fun_name : Optional [ str ] = None ) -> int : \"\"\"Tests that `x` is a vector; aborts otherwise Args: x: a potential vector fun_name: the name of the calling function Returns: the size of `x` if it is a vector \"\"\" fun_str = [ \"\" if fun_name is None else fun_name + \":\" ] if not isinstance ( x , np . ndarray ): bs_error_abort ( f \" { fun_str } x should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 1 : bs_error_abort ( f \" { fun_str } x should have one dimension, not { ndims_x } \" ) sx : int = x . size return sx","title":"General Utilities"},{"location":"utils/#utils-module","text":"This module contains some utility programs used by the package.","title":"utils module"},{"location":"utils/#bs_cupid_try.utils.ScalarFunctionAndGradient","text":"Type of f(v, args, gr) that returns a scalar value and also a gradient if gr is True","title":"ScalarFunctionAndGradient"},{"location":"utils/#bs_cupid_try.utils.bs_error_abort","text":"Report error and exits with code 1 Parameters: Name Type Description Default msg str specifies the error message 'error, aborting' Returns: Type Description None nothing Source code in bs_cupid_try/utils.py 72 73 74 75 76 77 78 79 80 81 82 def bs_error_abort ( msg : str = \"error, aborting\" ) -> None : \"\"\"Report error and exits with code 1 Args: msg: specifies the error message Returns: nothing \"\"\" print_stars ( f \" { bs_name_func ( 3 ) } : { msg } \" ) sys . exit ( 1 )","title":"bs_error_abort()"},{"location":"utils/#bs_cupid_try.utils.bs_name_func","text":"Get the name of the current function, or further back in the stack Parameters: Name Type Description Default back int 2 for the current function, 3 for the function that called it, etc 2 Returns: Type Description str the name of the function requested Source code in bs_cupid_try/utils.py 39 40 41 42 43 44 45 46 47 48 49 50 def bs_name_func ( back : int = 2 ) -> str : \"\"\"Get the name of the current function, or further back in the stack Args: back: 2 for the current function, 3 for the function that called it, etc Returns: the name of the function requested \"\"\" stack = extract_stack () func_name : str = stack [ - back ][ 2 ] return func_name","title":"bs_name_func()"},{"location":"utils/#bs_cupid_try.utils.check_gradient_scalar_function","text":"Checks the gradient of a scalar function. Parameters: Name Type Description Default fg Any should return the scalar value, and the gradient if its gr argument is True required p np . ndarray where we are checking the gradient required args list [ Any ] other arguments passed to fg required mode str \"central\" or \"forward\" derivatives 'central' EPS float the step for forward or central derivatives 1e-06 Returns: Type Description tuple [ np . ndarray , np . ndarray ] the analytic and numeric gradients Source code in bs_cupid_try/utils.py 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 def check_gradient_scalar_function ( fg : Any , p : np . ndarray , args : list [ Any ], mode : str = \"central\" , EPS : float = 1e-6 , ) -> tuple [ np . ndarray , np . ndarray ]: \"\"\"Checks the gradient of a scalar function. Args: fg: should return the scalar value, and the gradient if its `gr` argument is `True` p: where we are checking the gradient args: other arguments passed to `fg` mode: \"central\" or \"forward\" derivatives EPS: the step for forward or central derivatives Returns: the analytic and numeric gradients \"\"\" # if not isinstance(fg, ScalarFunctionAndGradient): # bs_error_abort(\"wrong type for fg\") f0 , f_grad = fg ( p , args , True ) print_stars ( \"checking the gradient: analytic, numeric\" ) g = np . zeros_like ( p ) sp : int = p . size if mode == \"central\" : for i in range ( sp ): x = p [ i ] p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , False ) p1 [ i ] -= 2.0 * EPS f_minus = fg ( p1 , args , False ) g [ i ] = ( f_plus - f_minus ) / ( 2.0 * EPS ) print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) elif mode == \"forward\" : for i in range ( sp ): x = p [ i ] p1 = p . copy () p1 [ i ] = x + EPS f_plus = fg ( p1 , args , False ) g [ i ] = ( f_plus - f0 ) / EPS print ( f \" { i } : { f_grad [ i ] } , { g [ i ] } \" ) else : bs_error_abort ( \"mode must be 'central' or 'forward'\" ) return f_grad , g","title":"check_gradient_scalar_function()"},{"location":"utils/#bs_cupid_try.utils.der_nppow","text":"evaluates the derivatives in a and b of element-by-element $a^b$ Parameters: Name Type Description Default a np . ndarray input Numpy arrays required b int | float | np . ndarray a Numpy array of the same shape, or a scalar required Returns: Type Description TwoArrays a pair of two arrays of the same shape as a Source code in bs_cupid_try/utils.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def der_nppow ( a : np . ndarray , b : int | float | np . ndarray ) -> TwoArrays : \"\"\" evaluates the derivatives in a and b of element-by-element $a^b$ Args: a: input Numpy arrays b: a Numpy array of the same shape, or a scalar Returns: a pair of two arrays of the same shape as `a` \"\"\" mina : float = np . min ( a ) if mina <= 0 : print_stars ( \"All elements of a must be positive in der_nppow!\" ) sys . exit ( 1 ) if isinstance ( b , ( int , float )): a_pow_b = np . power ( a , b ) return ( b * a_pow_b / a , a_pow_b * log ( a )) else : if a . shape != b . shape : print_stars ( \"nppow: b is not a number or an array of the same shape as a!\" ) sys . exit ( 1 ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape )","title":"der_nppow()"},{"location":"utils/#bs_cupid_try.utils.describe_array","text":"Descriptive statistics on an array interpreted as a vector Parameters: Name Type Description Default v np . ndarray the array required name str its name 'The array' Returns: Type Description NamedTuple a DescribeResult namedtuple Source code in bs_cupid_try/utils.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def describe_array ( v : np . ndarray , name : str = \"The array\" ) -> NamedTuple : \"\"\"Descriptive statistics on an array interpreted as a vector Args: v: the array name: its name Returns: a `DescribeResult` namedtuple \"\"\" print_stars ( f \" { name } has:\" ) d = sts . describe ( v , None ) print ( f \"Number of elements: { d . nobs } \" ) print ( f \"Minimum: { d . minmax [ 0 ] } \" ) print ( f \"Maximum: { d . minmax [ 1 ] } \" ) print ( f \"Mean: { d . mean } \" ) print ( f \"Stderr: { sqrt ( d . variance ) } \" ) return d","title":"describe_array()"},{"location":"utils/#bs_cupid_try.utils.npexp","text":"$C^2$ extension of $\\exp(a)$ above bigx Parameters: Name Type Description Default a np . ndarray a Numpy array required deriv bool if True , the first derivative is also returned False bigx float an upper bound 30.0 verbose bool whether diagnoses are printed False Returns: Name Type Description bigx np . ndarray | TwoArrays upper bound $\\exp(a)$ $C^2$-extended above bigx , np . ndarray | TwoArrays with its derivative if deriv is True Source code in bs_cupid_try/utils.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 def npexp ( a : np . ndarray , deriv : bool = False , bigx : float = 30.0 , verbose : bool = False , ) -> np . ndarray | TwoArrays : \"\"\" $C^2$ extension of $\\exp(a)$ above `bigx` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned bigx: an upper bound verbose: whether diagnoses are printed Returns: bigx: upper bound $\\exp(a)$ $C^2$-extended above `bigx`, with its derivative if `deriv` is `True` \"\"\" if np . max ( a ) < bigx : expa = np . exp ( a ) return ( expa , expa ) if deriv else expa else : exparr = np . exp ( np . minimum ( a , bigx )) ebigx = exp ( bigx ) darr = a - bigx exparr_larger = ebigx * ( 1.0 + darr * ( 1.0 + 0.5 * darr )) if verbose : n_large_args = np . sum ( a > bigx ) if n_large_args > 0 : finals = \"s\" if n_large_args > 1 else \"\" print ( f \"npexp: { n_large_args } argument { finals } larger than { bigx } : maxi = { np . max ( a ) } \" ) expa = np . where ( a < bigx , exparr , exparr_larger ) if deriv : der_exparr = np . exp ( np . minimum ( a , bigx )) der_exparr_larger = ebigx * ( 1.0 + darr ) der_expa = np . where ( a < bigx , der_exparr , der_exparr_larger ) return expa , der_expa else : return expa","title":"npexp()"},{"location":"utils/#bs_cupid_try.utils.nplog","text":"$C^2$ extension of $\\ln(a)$ below eps Parameters: Name Type Description Default a np . ndarray a Numpy array required deriv bool if True , the first derivative is also returned False eps float a lower bound 1e-30 verbose bool whether diagnoses are printed False Returns: Type Description np . ndarray | tuple [ np . ndarray , np . ndarray ] $\\ln(a)$ $C^2$-extended below eps , np . ndarray | tuple [ np . ndarray , np . ndarray ] with its derivative if deriv is True Source code in bs_cupid_try/utils.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def nplog ( a : np . ndarray , deriv : bool = False , eps : float = 1e-30 , verbose : bool = False , ) -> np . ndarray | tuple [ np . ndarray , np . ndarray ]: \"\"\"$C^2$ extension of $\\ln(a)$ below `eps` Args: a: a Numpy array deriv: if `True`, the first derivative is also returned eps: a lower bound verbose: whether diagnoses are printed Returns: $\\ln(a)$ $C^2$-extended below `eps`, with its derivative if `deriv` is `True` \"\"\" if np . min ( a ) > eps : loga = np . log ( a ) return ( loga , 1.0 / a ) if deriv else loga else : logarreps = np . log ( np . maximum ( a , eps )) logarr_smaller = log ( eps ) - ( eps - a ) * ( 3.0 * eps - a ) / ( 2.0 * eps * eps ) if verbose : n_small_args = np . sum ( a < eps ) if n_small_args > 0 : finals = \"s\" if n_small_args > 1 else \"\" print ( f \"nplog: { n_small_args } argument { finals } smaller than { eps } : mini = { np . min ( a ) } \" ) loga = np . where ( a > eps , logarreps , logarr_smaller ) if deriv : der_logarreps = 1.0 / np . maximum ( a , eps ) der_logarr_smaller = ( 2.0 * eps - a ) / ( eps * eps ) der_loga = np . where ( a > eps , der_logarreps , der_logarr_smaller ) return loga , der_loga else : return loga","title":"nplog()"},{"location":"utils/#bs_cupid_try.utils.npmaxabs","text":"The maximum absolute value in an array Parameters: Name Type Description Default a np . ndarray the array required Returns: Type Description float $\\max{ ert a ert}$ Source code in bs_cupid_try/utils.py 178 179 180 181 182 183 184 185 186 187 188 def npmaxabs ( a : np . ndarray ) -> float : \"\"\"The maximum absolute value in an array Args: a: the array Returns: $\\max{\\vert a \\vert}$ \"\"\" maxi : float = np . max ( np . abs ( a )) return maxi","title":"npmaxabs()"},{"location":"utils/#bs_cupid_try.utils.nppow","text":"Evaluates $a^b$ element-by-element Parameters: Name Type Description Default a np . ndarray a Numpy array required b int | float | np . ndarray if an array, it should have the same shape as a required deriv bool if True , the first derivatives wrt a and b are also returned False Returns: Type Description np . ndarray | ThreeArrays an array of the same shape as a , and if deriv is True , np . ndarray | ThreeArrays the derivatives wrt a and b Source code in bs_cupid_try/utils.py 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 def nppow ( a : np . ndarray , b : int | float | np . ndarray , deriv : bool = False ) -> np . ndarray | ThreeArrays : \"\"\"Evaluates $a^b$ element-by-element Args: a: a Numpy array b: if an array, it should have the same shape as `a` deriv: if `True`, the first derivatives wrt `a` and `b` are also returned Returns: an array of the same shape as `a`, and if `deriv` is `True`, the derivatives wrt `a` and `b` \"\"\" mina = np . min ( a ) if mina <= 0 : bs_error_abort ( \"All elements of a must be positive!\" ) if isinstance ( b , ( int , float )): a_pow_b = a ** b if deriv : return ( a ** b , b * a_pow_b / a , a_pow_b * log ( a )) else : return a_pow_b else : if a . shape != b . shape : bs_error_abort ( f \"a has shape { a . shape } and b has shape { b . shape } \" ) avec = a . ravel () bvec = b . ravel () a_pow_b = avec ** bvec if deriv : der_wrt_a = a_pow_b * bvec / avec der_wrt_b = a_pow_b * nplog ( avec ) return ( a_pow_b . reshape ( a . shape ), der_wrt_a . reshape ( a . shape ), der_wrt_b . reshape ( a . shape ), ) else : return a_pow_b . reshape ( a . shape )","title":"nppow()"},{"location":"utils/#bs_cupid_try.utils.nprepeat_col","text":"Creates a matrix with n columns, all equal to v Parameters: Name Type Description Default v np . ndarray a vector of size m required n int the number of columns requested required :return: a matrix of shape (m, n) Source code in bs_cupid_try/utils.py 149 150 151 152 153 154 155 156 157 158 159 160 def nprepeat_col ( v : np . ndarray , n : int ) -> np . ndarray : \"\"\"Creates a matrix with `n` columns, all equal to `v` Args: v: a vector of size `m` n: the number of columns requested :return: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_col\" ) w : np . ndarray = v [:, np . newaxis ] return np . repeat ( w , n , axis = 1 )","title":"nprepeat_col()"},{"location":"utils/#bs_cupid_try.utils.nprepeat_row","text":"Creates a matrix with m rows, all equal to v Parameters: Name Type Description Default v np . ndarray a vector of size n required m int the number of rows requested required Returns: Type Description np . ndarray a matrix of shape (m, n) Source code in bs_cupid_try/utils.py 163 164 165 166 167 168 169 170 171 172 173 174 175 def nprepeat_row ( v : np . ndarray , m : int ) -> np . ndarray : \"\"\" Creates a matrix with `m` rows, all equal to `v` Args: v: a vector of size `n` m: the number of rows requested Returns: a matrix of shape `(m, n)` \"\"\" _ = test_vector ( v , \"nprepeat_row\" ) return np . repeat ( v [ np . newaxis , :], m , axis = 0 )","title":"nprepeat_row()"},{"location":"utils/#bs_cupid_try.utils.print_stars","text":"Prints a starred line, or two around the title Parameters: Name Type Description Default title Optional [ str ] an optional title None n int the number of stars on the line 70 Returns: Type Description None nothing Source code in bs_cupid_try/utils.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def print_stars ( title : Optional [ str ] = None , n : int = 70 ) -> None : \"\"\"Prints a starred line, or two around the title Args: title: an optional title n: the number of stars on the line Returns: nothing \"\"\" line_stars = \"*\" * n print () print ( line_stars ) if title : print ( title . center ( n )) print ( line_stars ) print ()","title":"print_stars()"},{"location":"utils/#bs_cupid_try.utils.test_matrix","text":"Tests that x is a matrix; aborts otherwise Parameters: Name Type Description Default x Any a potential matrix required fun_name Optional [ str ] the name of the calling function None Returns: Type Description tuple [ int , int ] the shape of x if it is a matrix Source code in bs_cupid_try/utils.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def test_matrix ( x : Any , fun_name : Optional [ str ] = None ) -> tuple [ int , int ]: \"\"\"Tests that `x` is a matrix; aborts otherwise Args: x: a potential matrix fun_name: the name of the calling function Returns: the shape of `x` if it is a matrix \"\"\" fun_str : str = \"\" if fun_name is None else fun_name + \":\" if not isinstance ( x , np . ndarray ): bs_error_abort ( f \"x in { fun_str } should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 2 : bs_error_abort ( f \"x in { fun_str } should have two dimensions, not { ndims_x } \" ) shx : tuple [ int , int ] = x . shape return shx","title":"test_matrix()"},{"location":"utils/#bs_cupid_try.utils.test_vector","text":"Tests that x is a vector; aborts otherwise Parameters: Name Type Description Default x Any a potential vector required fun_name Optional [ str ] the name of the calling function None Returns: Type Description int the size of x if it is a vector Source code in bs_cupid_try/utils.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def test_vector ( x : Any , fun_name : Optional [ str ] = None ) -> int : \"\"\"Tests that `x` is a vector; aborts otherwise Args: x: a potential vector fun_name: the name of the calling function Returns: the size of `x` if it is a vector \"\"\" fun_str = [ \"\" if fun_name is None else fun_name + \":\" ] if not isinstance ( x , np . ndarray ): bs_error_abort ( f \" { fun_str } x should be a Numpy array\" ) ndims_x = x . ndim if ndims_x != 1 : bs_error_abort ( f \" { fun_str } x should have one dimension, not { ndims_x } \" ) sx : int = x . size return sx","title":"test_vector()"}]}